{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b742b234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unnia\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\unnia\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\unnia\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "C:\\Users\\unnia\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\3284648654.py:13: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mibian\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from copy import deepcopy\n",
    "from keras.regularizers import l2\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, LeakyReLU, Input, Concatenate, Conv1D, MaxPooling1D, LSTM, Flatten, Dense, TimeDistributed, Dropout, BatchNormalization, Bidirectional, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from numpy.random import seed\n",
    "from ta import add_all_ta_features\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.momentum import RSIIndicator\n",
    "from tensorflow import keras\n",
    "keras.utils.set_random_seed(812)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2799ce",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd8eab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073f8ab1",
   "metadata": {},
   "source": [
    "## TSLA data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c71e2aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2518326361.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TSLA['SMA'] = df_TSLA['UNDERLYING_LAST'].rolling(window=14).mean()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2518326361.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TSLA['EMA'] = df_TSLA['UNDERLYING_LAST'].ewm(span=14, adjust=False).mean()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2518326361.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TSLA['RSI'] = RSIIndicator(close=df_TSLA['UNDERLYING_LAST'], window=14).rsi()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2518326361.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TSLA['bb_bbm'] = indicator_bb.bollinger_mavg()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2518326361.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TSLA['bb_bbh'] = indicator_bb.bollinger_hband()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2518326361.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TSLA['bb_bbl'] = indicator_bb.bollinger_lband()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2518326361.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TSLA['realized_vol'] = df_TSLA['UNDERLYING_LAST'].pct_change().rolling(window=14).std() * np.sqrt(252)\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2518326361.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TSLA['C_LAST_lag1'] = df_TSLA['C_LAST'].shift(1)\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2518326361.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TSLA['C_IV_lag1'] = df_TSLA['C_IV'].shift(1)\n"
     ]
    }
   ],
   "source": [
    "df_TSLA = df[df['Stock_TSLA'] == 1.0]\n",
    "\n",
    "# Calculate Simple Moving Average\n",
    "df_TSLA['SMA'] = df_TSLA['UNDERLYING_LAST'].rolling(window=14).mean()\n",
    "\n",
    "# Calculate Exponential Moving Average\n",
    "df_TSLA['EMA'] = df_TSLA['UNDERLYING_LAST'].ewm(span=14, adjust=False).mean()\n",
    "\n",
    "# Calculate RSI\n",
    "df_TSLA['RSI'] = RSIIndicator(close=df_TSLA['UNDERLYING_LAST'], window=14).rsi()\n",
    "\n",
    "# Calculate Bollinger Bands\n",
    "indicator_bb = BollingerBands(close=df_TSLA['UNDERLYING_LAST'], window=20, window_dev=2)\n",
    "df_TSLA['bb_bbm'] = indicator_bb.bollinger_mavg()\n",
    "df_TSLA['bb_bbh'] = indicator_bb.bollinger_hband()\n",
    "df_TSLA['bb_bbl'] = indicator_bb.bollinger_lband()\n",
    "\n",
    "# Realized Volatility\n",
    "df_TSLA['realized_vol'] = df_TSLA['UNDERLYING_LAST'].pct_change().rolling(window=14).std() * np.sqrt(252)\n",
    "\n",
    "\n",
    "# For lagged features of the target variable, C_LAST:\n",
    "df_TSLA['C_LAST_lag1'] = df_TSLA['C_LAST'].shift(1)\n",
    "# For other variables, you could do the same:\n",
    "df_TSLA['C_IV_lag1'] = df_TSLA['C_IV'].shift(1)\n",
    "\n",
    "\n",
    "df_TSLA = df_TSLA[['C_IV_lag1','C_LAST_lag1','bb_bbm','bb_bbh','bb_bbl','SMA','EMA','RSI', 'realized_vol','UNDERLYING_LAST', 'STRIKE', 'DTE', 'C_IV', 'C_DELTA', 'C_GAMMA', 'C_VEGA', 'C_THETA', 'C_RHO', 'C_VOLUME', 'STRIKE_DISTANCE', 'STRIKE_DISTANCE_PCT', 'interest rate', 'dividend_rate','C_LAST']]\n",
    "df_TSLA = df_TSLA.dropna()\n",
    "\n",
    "# Find indices where C_IV or DTE is zero\n",
    "indices_to_remove = df_TSLA[(df_TSLA['C_IV'] == 0) | (df_TSLA['DTE'] == 0)].index\n",
    "\n",
    "# Drop these indices from the DataFrame\n",
    "df_TSLA = df_TSLA.drop(indices_to_remove)\n",
    "\n",
    "# Reset the index\n",
    "df_TSLA = df_TSLA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8fda06",
   "metadata": {},
   "source": [
    "## AAPL data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46bac19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2192086726.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AAPL['SMA'] = df_AAPL['UNDERLYING_LAST'].rolling(window=14).mean()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2192086726.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AAPL['EMA'] = df_AAPL['UNDERLYING_LAST'].ewm(span=14, adjust=False).mean()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2192086726.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AAPL['RSI'] = RSIIndicator(close=df_AAPL['UNDERLYING_LAST'], window=14).rsi()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2192086726.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AAPL['bb_bbm'] = indicator_bb.bollinger_mavg()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2192086726.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AAPL['bb_bbh'] = indicator_bb.bollinger_hband()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2192086726.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AAPL['bb_bbl'] = indicator_bb.bollinger_lband()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2192086726.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AAPL['realized_vol'] = df_AAPL['UNDERLYING_LAST'].pct_change().rolling(window=14).std() * np.sqrt(252)\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2192086726.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AAPL['C_LAST_lag1'] = df_AAPL['C_LAST'].shift(1)\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2192086726.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AAPL['C_IV_lag1'] = df_AAPL['C_IV'].shift(1)\n"
     ]
    }
   ],
   "source": [
    "df_AAPL = df[df['Stock_AAPL'] == 1.0]\n",
    "\n",
    "# Calculate Simple Moving Average\n",
    "df_AAPL['SMA'] = df_AAPL['UNDERLYING_LAST'].rolling(window=14).mean()\n",
    "\n",
    "# Calculate Exponential Moving Average\n",
    "df_AAPL['EMA'] = df_AAPL['UNDERLYING_LAST'].ewm(span=14, adjust=False).mean()\n",
    "\n",
    "# Calculate RSI\n",
    "df_AAPL['RSI'] = RSIIndicator(close=df_AAPL['UNDERLYING_LAST'], window=14).rsi()\n",
    "\n",
    "# Calculate Bollinger Bands\n",
    "indicator_bb = BollingerBands(close=df_AAPL['UNDERLYING_LAST'], window=20, window_dev=2)\n",
    "df_AAPL['bb_bbm'] = indicator_bb.bollinger_mavg()\n",
    "df_AAPL['bb_bbh'] = indicator_bb.bollinger_hband()\n",
    "df_AAPL['bb_bbl'] = indicator_bb.bollinger_lband()\n",
    "\n",
    "# Realized Volatility\n",
    "df_AAPL['realized_vol'] = df_AAPL['UNDERLYING_LAST'].pct_change().rolling(window=14).std() * np.sqrt(252)\n",
    "\n",
    "\n",
    "# For lagged features of the target variable, C_LAST:\n",
    "df_AAPL['C_LAST_lag1'] = df_AAPL['C_LAST'].shift(1)\n",
    "# For other variables, you could do the same:\n",
    "df_AAPL['C_IV_lag1'] = df_AAPL['C_IV'].shift(1)\n",
    "\n",
    "\n",
    "df_AAPL = df_AAPL[['C_IV_lag1','C_LAST_lag1','bb_bbm','bb_bbh','bb_bbl','SMA','EMA','RSI', 'realized_vol','UNDERLYING_LAST', 'STRIKE', 'DTE', 'C_IV', 'C_DELTA', 'C_GAMMA', 'C_VEGA', 'C_THETA', 'C_RHO', 'C_VOLUME', 'STRIKE_DISTANCE', 'STRIKE_DISTANCE_PCT', 'interest rate','dividend_rate', 'C_LAST']]\n",
    "df_AAPL = df_AAPL.dropna()\n",
    "\n",
    "# Find indices where C_IV or DTE is zero\n",
    "indices_to_remove = df_AAPL[(df_AAPL['C_IV'] == 0) | (df_AAPL['DTE'] == 0)].index\n",
    "\n",
    "# Drop these indices from the DataFrame\n",
    "df_AAPL = df_AAPL.drop(indices_to_remove)\n",
    "\n",
    "# Reset the index\n",
    "df_AAPL = df_AAPL.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36911fba",
   "metadata": {},
   "source": [
    "## NVDA data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f47bc1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\1211373322.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_NVDA['SMA'] = df_NVDA['UNDERLYING_LAST'].rolling(window=14).mean()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\1211373322.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_NVDA['EMA'] = df_NVDA['UNDERLYING_LAST'].ewm(span=14, adjust=False).mean()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\1211373322.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_NVDA['RSI'] = RSIIndicator(close=df_NVDA['UNDERLYING_LAST'], window=14).rsi()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\1211373322.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_NVDA['bb_bbm'] = indicator_bb.bollinger_mavg()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\1211373322.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_NVDA['bb_bbh'] = indicator_bb.bollinger_hband()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\1211373322.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_NVDA['bb_bbl'] = indicator_bb.bollinger_lband()\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\1211373322.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_NVDA['realized_vol'] = df_NVDA['UNDERLYING_LAST'].pct_change().rolling(window=14).std() * np.sqrt(252)\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\1211373322.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_NVDA['C_LAST_lag1'] = df_NVDA['C_LAST'].shift(1)\n",
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\1211373322.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_NVDA['C_IV_lag1'] = df_NVDA['C_IV'].shift(1)\n"
     ]
    }
   ],
   "source": [
    "df_NVDA = df[df['Stock_NVDA'] == 1.0]\n",
    "\n",
    "# Calculate Simple Moving Average\n",
    "df_NVDA['SMA'] = df_NVDA['UNDERLYING_LAST'].rolling(window=14).mean()\n",
    "\n",
    "# Calculate Exponential Moving Average\n",
    "df_NVDA['EMA'] = df_NVDA['UNDERLYING_LAST'].ewm(span=14, adjust=False).mean()\n",
    "\n",
    "# Calculate RSI\n",
    "df_NVDA['RSI'] = RSIIndicator(close=df_NVDA['UNDERLYING_LAST'], window=14).rsi()\n",
    "\n",
    "# Calculate Bollinger Bands\n",
    "indicator_bb = BollingerBands(close=df_NVDA['UNDERLYING_LAST'], window=20, window_dev=2)\n",
    "df_NVDA['bb_bbm'] = indicator_bb.bollinger_mavg()\n",
    "df_NVDA['bb_bbh'] = indicator_bb.bollinger_hband()\n",
    "df_NVDA['bb_bbl'] = indicator_bb.bollinger_lband()\n",
    "\n",
    "# Realized Volatility\n",
    "df_NVDA['realized_vol'] = df_NVDA['UNDERLYING_LAST'].pct_change().rolling(window=14).std() * np.sqrt(252)\n",
    "\n",
    "\n",
    "# For lagged features of the target variable, C_LAST:\n",
    "df_NVDA['C_LAST_lag1'] = df_NVDA['C_LAST'].shift(1)\n",
    "# For other variables, you could do the same:\n",
    "df_NVDA['C_IV_lag1'] = df_NVDA['C_IV'].shift(1)\n",
    "\n",
    "\n",
    "df_NVDA = df_NVDA[['C_IV_lag1','C_LAST_lag1','bb_bbm','bb_bbh','bb_bbl','SMA','EMA','RSI', 'realized_vol','UNDERLYING_LAST', 'STRIKE', 'DTE', 'C_IV', 'C_DELTA', 'C_GAMMA', 'C_VEGA', 'C_THETA', 'C_RHO', 'C_VOLUME', 'STRIKE_DISTANCE', 'STRIKE_DISTANCE_PCT', 'interest rate','dividend_rate', 'C_LAST']]\n",
    "df_NVDA = df_NVDA.dropna()\n",
    "\n",
    "# Find indices where C_IV or DTE is zero\n",
    "indices_to_remove = df_NVDA[(df_NVDA['C_IV'] == 0) | (df_NVDA['DTE'] == 0)].index\n",
    "\n",
    "# Drop these indices from the DataFrame\n",
    "df_NVDA = df_NVDA.drop(indices_to_remove)\n",
    "\n",
    "# Reset the index\n",
    "df_NVDA = df_NVDA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a96df",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5222cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features to use for prediction\n",
    "features = ['C_IV_lag1','C_LAST_lag1','bb_bbm','bb_bbh','bb_bbl','SMA','EMA','RSI', 'realized_vol', 'UNDERLYING_LAST', 'STRIKE', 'DTE', 'C_IV', 'C_DELTA', 'C_GAMMA', 'C_VEGA', 'C_THETA', 'C_RHO', 'C_VOLUME', 'STRIKE_DISTANCE', 'STRIKE_DISTANCE_PCT', 'interest rate','dividend_rate']\n",
    "target = 'C_LAST'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7cc106",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72330b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  # Monitor the validation set loss\n",
    "                               patience=10,         # Number of epochs with no improvement after which training will be stopped\n",
    "                               verbose=1,           # Output a message for each epoch where the training stops\n",
    "                               restore_best_weights=True)  # Restore model weights from the epoch with the best value of the monitored quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cb2cb",
   "metadata": {},
   "source": [
    "# Subset Data for MNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b3d9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the moneyness thresholds\n",
    "itm_threshold = 0.03  # In-the-money threshold\n",
    "otm_threshold = -0.03  # Out-of-the-money threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa960e",
   "metadata": {},
   "source": [
    "## Subset TSLA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baec78d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\2325937892.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TSLA_train['PERCENT_DISTANCE'] = (df_TSLA_train['UNDERLYING_LAST'] - df_TSLA_train['STRIKE']) / df_TSLA_train['STRIKE']\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "train_size_TSLA = int(len(df_TSLA) * 0.8)\n",
    "df_TSLA_train, df_TSLA_test = df_TSLA[:train_size_TSLA], df_TSLA[train_size_TSLA:]\n",
    "\n",
    "# Calculate the percentage distance from the underlying price to the strike price\n",
    "df_TSLA_train['PERCENT_DISTANCE'] = (df_TSLA_train['UNDERLYING_LAST'] - df_TSLA_train['STRIKE']) / df_TSLA_train['STRIKE']\n",
    "\n",
    "# Create subsets based on moneyness\n",
    "itm_options_TSLA = df_TSLA_train[df_TSLA_train['PERCENT_DISTANCE'] > itm_threshold]  # More than 3% above the strike price\n",
    "atm_options_TSLA = df_TSLA_train[(df_TSLA_train['PERCENT_DISTANCE'] <= itm_threshold) & (df_TSLA_train['PERCENT_DISTANCE'] >= otm_threshold)]  # Within +/-3%\n",
    "otm_options_TSLA = df_TSLA_train[df_TSLA_train['PERCENT_DISTANCE'] < otm_threshold]  # More than 3% below the strike price\n",
    "\n",
    "# Prepare the data for each subset\n",
    "X_itm_TSLA = itm_options_TSLA[features]\n",
    "y_itm_TSLA = itm_options_TSLA[target]\n",
    "X_atm_TSLA = atm_options_TSLA[features]\n",
    "y_atm_TSLA = atm_options_TSLA[target]\n",
    "X_otm_TSLA = otm_options_TSLA[features]\n",
    "y_otm_TSLA = otm_options_TSLA[target]\n",
    "\n",
    "# Initialize Scalar\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale the features for ITM options\n",
    "X_itm_TSLA_scaled = scaler.fit_transform(X_itm_TSLA)\n",
    "# Scale the features for ATM options\n",
    "X_atm_TSLA_scaled = scaler.fit_transform(X_atm_TSLA)\n",
    "# Scale the features for OTM options\n",
    "X_otm_TSLA_scaled = scaler.fit_transform(X_otm_TSLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0687a17c",
   "metadata": {},
   "source": [
    "## Subset AAPL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d2c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\1823318902.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AAPL_train['PERCENT_DISTANCE'] = (df_AAPL_train['UNDERLYING_LAST'] - df_AAPL_train['STRIKE']) / df_AAPL_train['STRIKE']\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "train_size_AAPL = int(len(df_AAPL) * 0.8)\n",
    "df_AAPL_train, df_AAPL_test = df_AAPL[:train_size_AAPL], df_AAPL[train_size_AAPL:]\n",
    "\n",
    "# Calculate the percentage distance from the underlying price to the strike price\n",
    "df_AAPL_train['PERCENT_DISTANCE'] = (df_AAPL_train['UNDERLYING_LAST'] - df_AAPL_train['STRIKE']) / df_AAPL_train['STRIKE']\n",
    "\n",
    "# Create subsets based on moneyness\n",
    "itm_options_AAPL = df_AAPL_train[df_AAPL_train['PERCENT_DISTANCE'] > itm_threshold]  # More than 3% above the strike price\n",
    "atm_options_AAPL = df_AAPL_train[(df_AAPL_train['PERCENT_DISTANCE'] <= itm_threshold) & (df_AAPL_train['PERCENT_DISTANCE'] >= otm_threshold)]  # Within +/-3%\n",
    "otm_options_AAPL = df_AAPL_train[df_AAPL_train['PERCENT_DISTANCE'] < otm_threshold]  # More than 3% below the strike price\n",
    "\n",
    "# Prepare the data for each subset\n",
    "X_itm_AAPL = itm_options_AAPL[features]\n",
    "y_itm_AAPL = itm_options_AAPL[target]\n",
    "X_atm_AAPL = atm_options_AAPL[features]\n",
    "y_atm_AAPL = atm_options_AAPL[target]\n",
    "X_otm_AAPL = otm_options_AAPL[features]\n",
    "y_otm_AAPL = otm_options_AAPL[target]\n",
    "\n",
    "\n",
    "# Initialize Scalar\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale the features for ITM options\n",
    "X_itm_AAPL_scaled = scaler.fit_transform(X_itm_AAPL)\n",
    "# Scale the features for ATM options\n",
    "X_atm_AAPL_scaled = scaler.fit_transform(X_atm_AAPL)\n",
    "# Scale the features for OTM options\n",
    "X_otm_AAPL_scaled = scaler.fit_transform(X_otm_AAPL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c398b",
   "metadata": {},
   "source": [
    "## Subset NVDA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d59c51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unnia\\AppData\\Local\\Temp\\ipykernel_98176\\3625806300.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_NVDA_train['PERCENT_DISTANCE'] = (df_NVDA_train['UNDERLYING_LAST'] - df_NVDA_train['STRIKE']) / df_NVDA_train['STRIKE']\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "train_size_NVDA = int(len(df_NVDA) * 0.8)\n",
    "df_NVDA_train, df_NVDA_test = df_NVDA[:train_size_NVDA], df_NVDA[train_size_NVDA:]\n",
    "\n",
    "# Calculate the percentage distance from the underlying price to the strike price\n",
    "df_NVDA_train['PERCENT_DISTANCE'] = (df_NVDA_train['UNDERLYING_LAST'] - df_NVDA_train['STRIKE']) / df_NVDA_train['STRIKE']\n",
    "\n",
    "# Create subsets based on moneyness\n",
    "itm_options_NVDA = df_NVDA_train[df_NVDA_train['PERCENT_DISTANCE'] > itm_threshold]  # More than 3% above the strike price\n",
    "atm_options_NVDA = df_NVDA_train[(df_NVDA_train['PERCENT_DISTANCE'] <= itm_threshold) & (df_NVDA_train['PERCENT_DISTANCE'] >= otm_threshold)]  # Within +/-3%\n",
    "otm_options_NVDA = df_NVDA_train[df_NVDA_train['PERCENT_DISTANCE'] < otm_threshold]  # More than 3% below the strike price\n",
    "\n",
    "# Prepare the data for each subset\n",
    "X_itm_NVDA = itm_options_NVDA[features]\n",
    "y_itm_NVDA = itm_options_NVDA[target]\n",
    "X_atm_NVDA = atm_options_NVDA[features]\n",
    "y_atm_NVDA = atm_options_NVDA[target]\n",
    "X_otm_NVDA = otm_options_NVDA[features]\n",
    "y_otm_NVDA = otm_options_NVDA[target]\n",
    "\n",
    "# Initialize Scalar\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale the features for ITM options\n",
    "X_itm_NVDA_scaled = scaler.fit_transform(X_itm_NVDA)\n",
    "# Scale the features for ATM options\n",
    "X_atm_NVDA_scaled = scaler.fit_transform(X_atm_NVDA)\n",
    "# Scale the features for OTM options\n",
    "X_otm_NVDA_scaled = scaler.fit_transform(X_otm_NVDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c77ee",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c23f8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_module(input_shape, neurons_per_layer, num_layers, activation, l2_reg=0.01):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    hidden_layer = input_layer\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        hidden_layer = Dense(neurons_per_layer[i], activation=activation, kernel_regularizer=l2(l2_reg))(hidden_layer)\n",
    "    \n",
    "    output_layer = Dense(1, activation='linear')(hidden_layer)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdab9a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 1175.6766 - val_loss: 555.2305\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 291.9632 - val_loss: 510.4247\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 286.2552 - val_loss: 499.8477\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 285.1679 - val_loss: 515.7908\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 284.6495 - val_loss: 482.2440\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 284.6154 - val_loss: 496.6395\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 284.0229 - val_loss: 545.2126\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 283.5327 - val_loss: 493.7984\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 283.5952 - val_loss: 508.3944\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 283.2440 - val_loss: 470.3441\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 283.1251 - val_loss: 474.9407\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 282.8495 - val_loss: 474.1554\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 282.7602 - val_loss: 518.9327\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 282.9014 - val_loss: 501.3997\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 282.7280 - val_loss: 518.0110\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 282.5221 - val_loss: 533.7433\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 282.3192 - val_loss: 489.0126\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 282.0806 - val_loss: 505.9329\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 282.0004 - val_loss: 477.1934\n",
      "Epoch 20/50\n",
      "3079/3084 [============================>.] - ETA: 0s - loss: 281.4532Restoring model weights from the end of the best epoch: 10.\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 281.8766 - val_loss: 515.2018\n",
      "Epoch 20: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 2s 3ms/step - loss: 575.8970 - val_loss: 363.6086\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 132.7628 - val_loss: 91.9200\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 16.8054 - val_loss: 14.3835\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 7.6108 - val_loss: 8.9771\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 5.3379 - val_loss: 5.9786\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.5563 - val_loss: 4.9553\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.2269 - val_loss: 5.7028\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.0009 - val_loss: 5.8666\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.8163 - val_loss: 4.8096\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.6954 - val_loss: 4.8565\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.5556 - val_loss: 4.4809\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4365 - val_loss: 4.0257\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.3280 - val_loss: 4.7010\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2546 - val_loss: 3.4092\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1602 - val_loss: 4.0079\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1126 - val_loss: 3.4783\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0341 - val_loss: 3.4986\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9683 - val_loss: 2.9119\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9100 - val_loss: 3.0115\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8474 - val_loss: 3.5603\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7718 - val_loss: 3.0886\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7479 - val_loss: 3.0267\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.6875 - val_loss: 2.6986\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6506 - val_loss: 2.4993\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6417 - val_loss: 2.4861\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5851 - val_loss: 2.7670\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5690 - val_loss: 3.1613\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5163 - val_loss: 2.3289\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4760 - val_loss: 2.6554\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4668 - val_loss: 3.0811\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4407 - val_loss: 2.4499\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3788 - val_loss: 2.4252\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3599 - val_loss: 2.7755\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3708 - val_loss: 2.2244\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3227 - val_loss: 2.1790\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2782 - val_loss: 2.4669\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2723 - val_loss: 2.7887\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2792 - val_loss: 2.0450\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2255 - val_loss: 2.8917\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2196 - val_loss: 2.1088\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1906 - val_loss: 2.7112\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1945 - val_loss: 2.5981\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1695 - val_loss: 2.2101\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1477 - val_loss: 2.1649\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1712 - val_loss: 2.1175\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1221 - val_loss: 2.0242\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1005 - val_loss: 2.0981\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0808 - val_loss: 2.0144\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0924 - val_loss: 1.9366\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0738 - val_loss: 1.9600\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 16s 3ms/step - loss: 18.5635 - val_loss: 3.5480\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 2.7224 - val_loss: 2.9055\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 2.3418 - val_loss: 3.1628\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.1564 - val_loss: 2.4242\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 2.0577 - val_loss: 2.5307\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.9833 - val_loss: 2.3843\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.9281 - val_loss: 2.3355\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8919 - val_loss: 2.1615\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8616 - val_loss: 2.3114\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8430 - val_loss: 2.0832\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8248 - val_loss: 2.1679\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.8082 - val_loss: 2.1140\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.7893 - val_loss: 2.1023\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.7791 - val_loss: 2.3833\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.7650 - val_loss: 2.0450\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.7628 - val_loss: 2.0981\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7475 - val_loss: 2.1370\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7477 - val_loss: 2.3100\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7366 - val_loss: 1.9579\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7300 - val_loss: 2.0488\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7200 - val_loss: 2.1508\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7215 - val_loss: 2.0146\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7212 - val_loss: 2.0964\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.7047 - val_loss: 2.1114\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7113 - val_loss: 1.9470\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7004 - val_loss: 1.9435\n",
      "Epoch 27/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6995 - val_loss: 1.9911\n",
      "Epoch 28/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6928 - val_loss: 1.9989\n",
      "Epoch 29/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6928 - val_loss: 1.9612\n",
      "Epoch 30/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6817 - val_loss: 1.9036\n",
      "Epoch 31/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6881 - val_loss: 1.9248\n",
      "Epoch 32/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6759 - val_loss: 2.7209\n",
      "Epoch 33/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.6792 - val_loss: 1.9637\n",
      "Epoch 34/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.6851 - val_loss: 1.9531\n",
      "Epoch 35/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6707 - val_loss: 1.9898\n",
      "Epoch 36/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6635 - val_loss: 1.8606\n",
      "Epoch 37/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6712 - val_loss: 1.8710\n",
      "Epoch 38/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6631 - val_loss: 1.9964\n",
      "Epoch 39/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6578 - val_loss: 2.7820\n",
      "Epoch 40/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6741 - val_loss: 2.7589\n",
      "Epoch 41/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6670 - val_loss: 2.0219\n",
      "Epoch 42/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6556 - val_loss: 1.9087\n",
      "Epoch 43/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6554 - val_loss: 1.9019\n",
      "Epoch 44/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6582 - val_loss: 1.8399\n",
      "Epoch 45/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6491 - val_loss: 1.8513\n",
      "Epoch 46/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6437 - val_loss: 2.3094\n",
      "Epoch 47/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6403 - val_loss: 2.0274\n",
      "Epoch 48/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6403 - val_loss: 2.2247\n",
      "Epoch 49/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6533 - val_loss: 1.9970\n",
      "Epoch 50/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6384 - val_loss: 1.9701\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 35s 4ms/step - loss: 147.6125 - val_loss: 238.0460\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 116.7772 - val_loss: 231.6330\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 114.6581 - val_loss: 201.9111\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 113.3386 - val_loss: 198.0741\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 112.4464 - val_loss: 180.8621\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 111.7527 - val_loss: 187.9557\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 27s 4ms/step - loss: 111.0400 - val_loss: 180.8015\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 110.5014 - val_loss: 204.5835\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 110.1965 - val_loss: 183.8204\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 27s 4ms/step - loss: 109.9259 - val_loss: 171.1036\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 109.4934 - val_loss: 185.4786\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 109.2551 - val_loss: 176.6700\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 109.3605 - val_loss: 229.5510\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 109.2386 - val_loss: 172.6435\n",
      "Epoch 15/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 109.4032 - val_loss: 200.5015\n",
      "Epoch 16/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 109.3059 - val_loss: 191.5895\n",
      "Epoch 17/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 109.1571 - val_loss: 178.7257\n",
      "Epoch 18/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 109.5630 - val_loss: 184.0213\n",
      "Epoch 19/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 109.4937 - val_loss: 196.2903\n",
      "Epoch 20/50\n",
      "7728/7741 [============================>.] - ETA: 0s - loss: 109.6302Restoring model weights from the end of the best epoch: 10.\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 109.6085 - val_loss: 177.8757\n",
      "Epoch 20: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 1141.8699 - val_loss: 580.8604\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 295.0078 - val_loss: 533.0181\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 289.5257 - val_loss: 522.0646\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 288.5639 - val_loss: 540.1287\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 288.1563 - val_loss: 501.2618\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 288.2563 - val_loss: 519.4877\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 287.7351 - val_loss: 570.6407\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.4621 - val_loss: 504.0447\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 287.4872 - val_loss: 521.7423\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 287.3492 - val_loss: 489.9312\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 287.2475 - val_loss: 493.4342\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 287.0016 - val_loss: 487.0854\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 286.8285 - val_loss: 533.6406\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.0002 - val_loss: 510.3947\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3084/3084 [==============================] - 8s 2ms/step - loss: 286.9341 - val_loss: 530.0369\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 7s 2ms/step - loss: 286.8108 - val_loss: 544.6476\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 7s 2ms/step - loss: 286.6615 - val_loss: 502.5538\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 286.4080 - val_loss: 515.4725\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 286.3599 - val_loss: 487.9455\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 286.2811 - val_loss: 526.5430\n",
      "Epoch 21/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 286.4068 - val_loss: 504.0548\n",
      "Epoch 22/50\n",
      "3071/3084 [============================>.] - ETA: 0s - loss: 286.2206Restoring model weights from the end of the best epoch: 12.\n",
      "3084/3084 [==============================] - 7s 2ms/step - loss: 286.0635 - val_loss: 524.0925\n",
      "Epoch 22: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 2s 3ms/step - loss: 485.2016 - val_loss: 356.8409\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 111.8069 - val_loss: 49.7859\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 12.6223 - val_loss: 14.3171\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 7.9415 - val_loss: 8.5517\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 5.8969 - val_loss: 5.9669\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.8652 - val_loss: 5.2933\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.3656 - val_loss: 5.1442\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.1022 - val_loss: 6.2608\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.9052 - val_loss: 5.2555\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.7962 - val_loss: 4.8792\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 3.6601 - val_loss: 4.1080\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.5335 - val_loss: 3.7989\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4519 - val_loss: 4.2146\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.3807 - val_loss: 3.5854\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 3.3055 - val_loss: 4.1785\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2529 - val_loss: 3.3672\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1968 - val_loss: 3.7944\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1152 - val_loss: 3.1928\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0545 - val_loss: 3.4564\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0220 - val_loss: 3.7707\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9511 - val_loss: 3.4590\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9443 - val_loss: 3.5504\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8818 - val_loss: 2.9643\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8660 - val_loss: 3.4161\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8308 - val_loss: 2.8285\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7939 - val_loss: 4.3846\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7730 - val_loss: 3.8848\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7492 - val_loss: 2.5134\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6971 - val_loss: 2.9873\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6868 - val_loss: 3.6765\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6978 - val_loss: 2.6769\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6314 - val_loss: 3.0106\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6081 - val_loss: 2.8941\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6175 - val_loss: 2.6015\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6124 - val_loss: 3.0306\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5577 - val_loss: 3.3809\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5364 - val_loss: 3.5474\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5509 - val_loss: 2.2891\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4950 - val_loss: 2.5460\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4884 - val_loss: 2.3928\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4756 - val_loss: 3.2744\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5096 - val_loss: 3.0184\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4729 - val_loss: 2.4250\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4673 - val_loss: 2.3555\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4607 - val_loss: 2.5605\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4222 - val_loss: 3.0049\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4140 - val_loss: 2.1392\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4148 - val_loss: 2.3732\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3976 - val_loss: 2.4925\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3852 - val_loss: 2.6511\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 17.4218 - val_loss: 4.2264\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 3.2068 - val_loss: 3.3532\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.8128 - val_loss: 3.1387\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.6400 - val_loss: 3.0253\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.5512 - val_loss: 2.8014\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.4920 - val_loss: 3.3309\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.4378 - val_loss: 2.7318\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.4110 - val_loss: 2.6234\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.3858 - val_loss: 2.9434\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.3620 - val_loss: 2.5738\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.3596 - val_loss: 2.5869\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 2.3343 - val_loss: 2.6297\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 10s 2ms/step - loss: 2.3359 - val_loss: 3.3459\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 10s 2ms/step - loss: 2.3288 - val_loss: 2.8277\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 2.3224 - val_loss: 2.6925\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 10s 2ms/step - loss: 2.3192 - val_loss: 4.0807\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 10s 2ms/step - loss: 2.2954 - val_loss: 2.4727\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 10s 2ms/step - loss: 2.3050 - val_loss: 2.6408\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 10s 2ms/step - loss: 2.2958 - val_loss: 2.6026\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 2.2956 - val_loss: 2.7479\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4377/4377 [==============================] - 11s 2ms/step - loss: 2.2948 - val_loss: 4.3502\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 2.3011 - val_loss: 2.7273\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.3182 - val_loss: 2.6485\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.3054 - val_loss: 2.5997\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.3027 - val_loss: 3.6987\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.2966 - val_loss: 2.5807\n",
      "Epoch 27/50\n",
      "4370/4377 [============================>.] - ETA: 0s - loss: 2.3110Restoring model weights from the end of the best epoch: 17.\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.3100 - val_loss: 2.5774\n",
      "Epoch 27: early stopping\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 200.4227 - val_loss: 288.1308\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 134.0228 - val_loss: 259.1242\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 128.6142 - val_loss: 225.9073\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 125.8956 - val_loss: 216.4603\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 124.2164 - val_loss: 211.7648\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 123.1387 - val_loss: 215.5055\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 27s 4ms/step - loss: 122.2492 - val_loss: 207.7491\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 121.5930 - val_loss: 253.3561\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 121.2592 - val_loss: 209.7718\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 120.7163 - val_loss: 198.7771\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 120.1485 - val_loss: 220.6969\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 119.7036 - val_loss: 206.1652\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 27s 4ms/step - loss: 119.8831 - val_loss: 237.4894\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 119.3070 - val_loss: 182.7895\n",
      "Epoch 15/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 119.1795 - val_loss: 222.3927\n",
      "Epoch 16/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 118.6901 - val_loss: 208.6045\n",
      "Epoch 17/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 118.4378 - val_loss: 213.6467\n",
      "Epoch 18/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 118.2355 - val_loss: 199.4141\n",
      "Epoch 19/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 117.8797 - val_loss: 233.7996\n",
      "Epoch 20/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 117.4222 - val_loss: 207.1846\n",
      "Epoch 21/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 117.0228 - val_loss: 201.5790\n",
      "Epoch 22/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 116.8077 - val_loss: 191.2997\n",
      "Epoch 23/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 116.2275 - val_loss: 203.3779\n",
      "Epoch 24/50\n",
      "7731/7741 [============================>.] - ETA: 0s - loss: 116.2727Restoring model weights from the end of the best epoch: 14.\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 116.3019 - val_loss: 205.4857\n",
      "Epoch 24: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 12s 3ms/step - loss: 1016.9062 - val_loss: 511.0915\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 288.8562 - val_loss: 505.3128\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 285.8063 - val_loss: 499.4360\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 285.0335 - val_loss: 524.2158\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 284.5898 - val_loss: 475.2487\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 284.6623 - val_loss: 497.8011\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 283.9212 - val_loss: 553.1627\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 283.3298 - val_loss: 503.2057\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 283.3148 - val_loss: 504.3597\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 282.8909 - val_loss: 469.5179\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 282.4507 - val_loss: 461.9157\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 281.9514 - val_loss: 473.0162\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 281.5456 - val_loss: 526.7791\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 281.4767 - val_loss: 491.0746\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 281.0326 - val_loss: 512.4153\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 280.4690 - val_loss: 538.0579\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 280.0181 - val_loss: 478.6867\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 279.6764 - val_loss: 499.1310\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 279.6114 - val_loss: 477.4920\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 279.4658 - val_loss: 500.0501\n",
      "Epoch 21/50\n",
      "3084/3084 [==============================] - ETA: 0s - loss: 279.1836Restoring model weights from the end of the best epoch: 11.\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 279.1836 - val_loss: 483.3552\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 2s 3ms/step - loss: 468.8142 - val_loss: 273.7038\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 55.5965 - val_loss: 19.5157\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 8.2487 - val_loss: 10.2266\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 5.2335 - val_loss: 6.4572\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.4177 - val_loss: 4.1857\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.0898 - val_loss: 3.8743\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.8511 - val_loss: 4.4687\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.6783 - val_loss: 5.4386\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.5302 - val_loss: 5.9649\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4271 - val_loss: 3.9404\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2872 - val_loss: 3.8447\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1798 - val_loss: 3.3172\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1108 - val_loss: 4.3718\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9797 - val_loss: 3.5463\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9547 - val_loss: 3.6666\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8629 - val_loss: 3.3061\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8119 - val_loss: 3.2813\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7478 - val_loss: 2.5778\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7161 - val_loss: 2.5873\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7046 - val_loss: 3.0311\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6202 - val_loss: 2.4140\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5451 - val_loss: 3.0586\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5161 - val_loss: 2.8146\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4876 - val_loss: 2.4439\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4463 - val_loss: 2.2613\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4301 - val_loss: 2.2521\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3921 - val_loss: 2.5784\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3324 - val_loss: 2.2939\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3648 - val_loss: 2.2795\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3115 - val_loss: 2.8430\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3336 - val_loss: 2.2578\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2340 - val_loss: 2.2334\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2319 - val_loss: 2.0473\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2212 - val_loss: 2.0981\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2244 - val_loss: 2.3675\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1960 - val_loss: 2.0547\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1811 - val_loss: 2.5253\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1616 - val_loss: 1.9223\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1348 - val_loss: 1.9005\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1275 - val_loss: 1.9623\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1022 - val_loss: 2.4443\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1068 - val_loss: 2.1179\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0809 - val_loss: 2.2602\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.0579 - val_loss: 2.0417\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.0534 - val_loss: 1.9975\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0306 - val_loss: 1.8050\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0592 - val_loss: 1.8398\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0135 - val_loss: 1.9516\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0793 - val_loss: 1.8584\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.9945 - val_loss: 1.6976\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 13.1502 - val_loss: 2.8944\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 2.2830 - val_loss: 2.5946\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.0081 - val_loss: 3.0329\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8807 - val_loss: 2.0886\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7975 - val_loss: 2.2439\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7507 - val_loss: 2.3175\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7039 - val_loss: 2.2305\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6682 - val_loss: 1.9522\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6543 - val_loss: 2.0393\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.6264 - val_loss: 1.8220\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.6201 - val_loss: 1.8160\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.6047 - val_loss: 1.8552\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.5918 - val_loss: 1.9358\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5749 - val_loss: 1.8020\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.5652 - val_loss: 1.8371\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5633 - val_loss: 1.8259\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5505 - val_loss: 2.0988\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5543 - val_loss: 1.7180\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5417 - val_loss: 1.8558\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5390 - val_loss: 1.8918\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5401 - val_loss: 1.8464\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5278 - val_loss: 2.1639\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5268 - val_loss: 2.0447\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5175 - val_loss: 1.9200\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5169 - val_loss: 2.2614\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5102 - val_loss: 1.7887\n",
      "Epoch 27/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5042 - val_loss: 1.9061\n",
      "Epoch 28/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5054 - val_loss: 1.6804\n",
      "Epoch 29/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5010 - val_loss: 1.9971\n",
      "Epoch 30/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.4954 - val_loss: 2.4543\n",
      "Epoch 31/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.4946 - val_loss: 2.2050\n",
      "Epoch 32/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.4949 - val_loss: 1.7505\n",
      "Epoch 33/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.4872 - val_loss: 1.9761\n",
      "Epoch 34/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.4774 - val_loss: 2.4028\n",
      "Epoch 35/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.4797 - val_loss: 1.8505\n",
      "Epoch 36/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.4783 - val_loss: 1.6457\n",
      "Epoch 37/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.4736 - val_loss: 1.7072\n",
      "Epoch 38/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.4743 - val_loss: 1.8746\n",
      "Epoch 39/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.4805 - val_loss: 3.4041\n",
      "Epoch 40/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.4802 - val_loss: 2.2477\n",
      "Epoch 41/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.4814 - val_loss: 1.7070\n",
      "Epoch 42/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.4709 - val_loss: 1.6627\n",
      "Epoch 43/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.4715 - val_loss: 1.7552\n",
      "Epoch 44/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.4779 - val_loss: 1.6194\n",
      "Epoch 45/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.4690 - val_loss: 1.8344\n",
      "Epoch 46/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.4693 - val_loss: 1.7363\n",
      "Epoch 47/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.4533 - val_loss: 1.7328\n",
      "Epoch 48/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.4573 - val_loss: 2.0020\n",
      "Epoch 49/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.4687 - val_loss: 1.7770\n",
      "Epoch 50/50\n",
      "4377/4377 [==============================] - 10s 2ms/step - loss: 1.4603 - val_loss: 3.2278\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7741/7741 [==============================] - 30s 3ms/step - loss: 138.3549 - val_loss: 263.3124\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 118.0781 - val_loss: 234.3306\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 115.5858 - val_loss: 230.6742\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 113.6972 - val_loss: 187.8671\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 27s 4ms/step - loss: 112.5615 - val_loss: 180.6670\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 111.9475 - val_loss: 187.1969\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 111.0507 - val_loss: 184.5509\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 27s 4ms/step - loss: 111.1885 - val_loss: 210.7898\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 110.9133 - val_loss: 178.7189\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 110.6866 - val_loss: 173.1230\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 110.6284 - val_loss: 187.0240\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 110.3461 - val_loss: 174.9357\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 110.6730 - val_loss: 220.7444\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 27s 4ms/step - loss: 110.5463 - val_loss: 170.8175\n",
      "Epoch 15/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 110.6115 - val_loss: 191.1613\n",
      "Epoch 16/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 110.4127 - val_loss: 186.7292\n",
      "Epoch 17/50\n",
      "7741/7741 [==============================] - 27s 4ms/step - loss: 110.7180 - val_loss: 191.8450\n",
      "Epoch 18/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 110.8893 - val_loss: 186.9508\n",
      "Epoch 19/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 110.9637 - val_loss: 193.5100\n",
      "Epoch 20/50\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 111.4609 - val_loss: 173.6329\n",
      "Epoch 21/50\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 111.9974 - val_loss: 185.8850\n",
      "Epoch 22/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 112.6785 - val_loss: 182.4782\n",
      "Epoch 23/50\n",
      "7741/7741 [==============================] - 27s 4ms/step - loss: 113.1749 - val_loss: 188.2721\n",
      "Epoch 24/50\n",
      "7737/7741 [============================>.] - ETA: 0s - loss: 113.5345Restoring model weights from the end of the best epoch: 14.\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 113.5823 - val_loss: 212.1871\n",
      "Epoch 24: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 871.8200 - val_loss: 545.5045\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 291.9104 - val_loss: 522.2840\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 289.7016 - val_loss: 519.7518\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 289.1151 - val_loss: 554.5058\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 288.8671 - val_loss: 490.6151\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 289.0497 - val_loss: 516.0082\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 288.3560 - val_loss: 583.7145\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.9518 - val_loss: 524.6532\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.9544 - val_loss: 514.0460\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.9895 - val_loss: 496.2005\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 287.8236 - val_loss: 476.3161\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.5139 - val_loss: 489.1142\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.4001 - val_loss: 557.5562\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.5681 - val_loss: 497.8116\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.4756 - val_loss: 538.3743\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.3429 - val_loss: 558.9817\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.1707 - val_loss: 491.3201\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 287.1308 - val_loss: 524.3561\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 8s 2ms/step - loss: 287.0698 - val_loss: 483.7979\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 286.9346 - val_loss: 518.0621\n",
      "Epoch 21/50\n",
      "3074/3084 [============================>.] - ETA: 0s - loss: 286.8807Restoring model weights from the end of the best epoch: 11.\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 287.1070 - val_loss: 502.0098\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 2s 3ms/step - loss: 381.6023 - val_loss: 234.5856\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 35.8905 - val_loss: 15.8427\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 7.5935 - val_loss: 9.4567\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 5.5002 - val_loss: 7.2137\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.7107 - val_loss: 4.1580\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.2741 - val_loss: 3.8333\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.9873 - val_loss: 6.9492\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.7957 - val_loss: 5.0042\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.6507 - val_loss: 6.2984\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.5514 - val_loss: 4.0909\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.3941 - val_loss: 3.4384\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.3487 - val_loss: 3.3398\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2524 - val_loss: 4.1384\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1256 - val_loss: 3.1948\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0931 - val_loss: 3.5582\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0079 - val_loss: 3.3663\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9879 - val_loss: 3.2375\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9101 - val_loss: 2.9966\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8985 - val_loss: 2.7761\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8637 - val_loss: 3.0758\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8520 - val_loss: 4.3913\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7547 - val_loss: 4.0430\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 3.5003\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6906 - val_loss: 4.1672\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7335 - val_loss: 2.4073\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6760 - val_loss: 3.4123\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6663 - val_loss: 3.6122\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6170 - val_loss: 2.9485\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5810 - val_loss: 2.7496\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5711 - val_loss: 3.6263\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 1s 4ms/step - loss: 2.5759 - val_loss: 2.7072\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.5800 - val_loss: 2.3260\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5454 - val_loss: 2.4938\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5034 - val_loss: 2.6951\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5331 - val_loss: 2.2376\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4564 - val_loss: 3.4399\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.4549 - val_loss: 3.3500\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4312 - val_loss: 2.3291\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4224 - val_loss: 2.1528\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4107 - val_loss: 2.2489\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4209 - val_loss: 2.7307\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4839 - val_loss: 2.0932\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4055 - val_loss: 3.1633\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3655 - val_loss: 2.2354\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3689 - val_loss: 2.1935\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3383 - val_loss: 1.9689\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3442 - val_loss: 2.5699\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3951 - val_loss: 2.0717\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3811 - val_loss: 2.1514\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3000 - val_loss: 1.9816\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 13.4077 - val_loss: 3.4337\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.7126 - val_loss: 2.8812\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.4040 - val_loss: 3.5372\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.2661 - val_loss: 2.5159\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.2018 - val_loss: 2.9476\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.1516 - val_loss: 5.0504\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.1107 - val_loss: 2.3731\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 2.0852 - val_loss: 2.3945\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 2.0495 - val_loss: 2.2874\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.0297 - val_loss: 2.7028\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 2.0149 - val_loss: 2.4416\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.9993 - val_loss: 2.2897\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.9864 - val_loss: 2.5255\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.9675 - val_loss: 2.3366\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.9504 - val_loss: 2.1330\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.9314 - val_loss: 2.8159\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.9139 - val_loss: 2.1850\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.9169 - val_loss: 2.3966\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.9158 - val_loss: 2.1533\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8890 - val_loss: 2.0974\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8924 - val_loss: 2.1224\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8818 - val_loss: 2.2997\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8596 - val_loss: 2.0505\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8453 - val_loss: 2.1104\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8583 - val_loss: 2.0085\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8333 - val_loss: 2.0701\n",
      "Epoch 27/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8307 - val_loss: 2.7094\n",
      "Epoch 28/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8138 - val_loss: 2.0336\n",
      "Epoch 29/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.8146 - val_loss: 2.2415\n",
      "Epoch 30/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.8024 - val_loss: 1.9778\n",
      "Epoch 31/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7917 - val_loss: 2.2033\n",
      "Epoch 32/50\n",
      "4377/4377 [==============================] - 11s 2ms/step - loss: 1.7878 - val_loss: 3.8250\n",
      "Epoch 33/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.7887 - val_loss: 2.1703\n",
      "Epoch 34/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7674 - val_loss: 2.1534\n",
      "Epoch 35/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.7718 - val_loss: 2.1419\n",
      "Epoch 36/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.7554 - val_loss: 2.6402\n",
      "Epoch 37/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.7617 - val_loss: 2.4612\n",
      "Epoch 38/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7444 - val_loss: 2.0012\n",
      "Epoch 39/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7372 - val_loss: 2.6114\n",
      "Epoch 40/50\n",
      "4372/4377 [============================>.] - ETA: 0s - loss: 1.7372Restoring model weights from the end of the best epoch: 30.\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.7394 - val_loss: 3.2501\n",
      "Epoch 40: early stopping\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 160.5263 - val_loss: 285.8749\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 129.1006 - val_loss: 261.3260\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 126.6836 - val_loss: 225.1636\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 125.0866 - val_loss: 220.3305\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 123.7248 - val_loss: 211.6425\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 123.0915 - val_loss: 231.6971\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 122.0820 - val_loss: 210.9293\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 121.2934 - val_loss: 258.0817\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 120.5813 - val_loss: 211.4549\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 119.6491 - val_loss: 206.1969\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 118.9144 - val_loss: 217.6181\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 118.5104 - val_loss: 198.3365\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 118.7933 - val_loss: 238.5764\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 118.2010 - val_loss: 184.6170\n",
      "Epoch 15/50\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 118.2837 - val_loss: 226.1401\n",
      "Epoch 16/50\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 117.7921 - val_loss: 212.6127\n",
      "Epoch 17/50\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 117.3586 - val_loss: 217.9959\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7741/7741 [==============================] - 27s 4ms/step - loss: 117.1303 - val_loss: 209.7494\n",
      "Epoch 19/50\n",
      "7741/7741 [==============================] - 27s 3ms/step - loss: 116.8751 - val_loss: 228.2755\n",
      "Epoch 20/50\n",
      "7741/7741 [==============================] - 27s 4ms/step - loss: 116.3435 - val_loss: 199.7466\n",
      "Epoch 21/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 115.8187 - val_loss: 202.1080\n",
      "Epoch 22/50\n",
      "7741/7741 [==============================] - 28s 4ms/step - loss: 116.0649 - val_loss: 193.7572\n",
      "Epoch 23/50\n",
      "7741/7741 [==============================] - 26s 3ms/step - loss: 115.7528 - val_loss: 202.0683\n",
      "Epoch 24/50\n",
      "7735/7741 [============================>.] - ETA: 0s - loss: 115.7596Restoring model weights from the end of the best epoch: 14.\n",
      "7741/7741 [==============================] - 25s 3ms/step - loss: 115.7950 - val_loss: 214.7390\n",
      "Epoch 24: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 635.2640 - val_loss: 494.2350\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 283.9393 - val_loss: 480.9549\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 282.0040 - val_loss: 450.5594\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 280.9946 - val_loss: 520.2436\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 279.0579 - val_loss: 438.7838\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 278.2186 - val_loss: 463.0373\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 275.1228 - val_loss: 534.4489\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 273.3314 - val_loss: 464.0221\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 272.1373 - val_loss: 463.0409\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 270.9937 - val_loss: 438.6073\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 270.0694 - val_loss: 379.4081\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 268.1042 - val_loss: 418.8584\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 267.3984 - val_loss: 518.2230\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 267.1087 - val_loss: 424.4104\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 266.3072 - val_loss: 457.2616\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 266.7271 - val_loss: 420.2820\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 266.2626 - val_loss: 404.5506\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 266.5920 - val_loss: 454.8050\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 266.0924 - val_loss: 490.4701\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 265.7041 - val_loss: 463.5296\n",
      "Epoch 21/50\n",
      "3071/3084 [============================>.] - ETA: 0s - loss: 265.1728Restoring model weights from the end of the best epoch: 11.\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 265.3819 - val_loss: 415.7973\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 2s 4ms/step - loss: 324.6650 - val_loss: 14.6941\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 6.0634 - val_loss: 5.6332\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.7393 - val_loss: 4.3263\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2471 - val_loss: 3.5681\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0810 - val_loss: 3.3912\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8417 - val_loss: 2.8672\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7439 - val_loss: 3.9063\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6899 - val_loss: 3.5364\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6395 - val_loss: 4.8489\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5831 - val_loss: 3.2284\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5355 - val_loss: 2.5056\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5189 - val_loss: 2.1985\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3922 - val_loss: 2.4216\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3560 - val_loss: 2.6337\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3870 - val_loss: 2.5308\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3388 - val_loss: 3.7390\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3185 - val_loss: 3.9525\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3703 - val_loss: 1.9185\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2909 - val_loss: 2.3181\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3934 - val_loss: 3.8894\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2875 - val_loss: 2.1414\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2215 - val_loss: 3.6989\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2517 - val_loss: 3.4400\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1735 - val_loss: 4.1353\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2447 - val_loss: 2.1614\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2481 - val_loss: 2.0988\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2027 - val_loss: 3.3527\n",
      "Epoch 28/50\n",
      "273/280 [============================>.] - ETA: 0s - loss: 2.1084Restoring model weights from the end of the best epoch: 18.\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1044 - val_loss: 2.8892\n",
      "Epoch 28: early stopping\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 8.4806 - val_loss: 2.5051\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 2.1907 - val_loss: 2.4850\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.0274 - val_loss: 2.6560\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.9407 - val_loss: 2.2056\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.8926 - val_loss: 2.0858\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.8586 - val_loss: 2.6646\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8060 - val_loss: 2.0452\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7733 - val_loss: 2.8694\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7540 - val_loss: 2.4266\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.7287 - val_loss: 1.9643\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.7079 - val_loss: 2.5051\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6938 - val_loss: 1.9051\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6739 - val_loss: 1.8582\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6619 - val_loss: 2.7640\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6461 - val_loss: 1.9068\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6512 - val_loss: 1.8901\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6432 - val_loss: 2.8459\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6390 - val_loss: 1.9118\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6310 - val_loss: 2.4831\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6303 - val_loss: 2.2170\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6144 - val_loss: 1.8859\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6089 - val_loss: 2.2703\n",
      "Epoch 23/50\n",
      "4363/4377 [============================>.] - ETA: 0s - loss: 1.5910Restoring model weights from the end of the best epoch: 13.\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.5909 - val_loss: 2.1900\n",
      "Epoch 23: early stopping\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 35s 4ms/step - loss: 200.1238 - val_loss: 265.3704\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 117.6312 - val_loss: 222.4609\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 114.4471 - val_loss: 224.3083\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 112.3642 - val_loss: 187.0669\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 111.2187 - val_loss: 168.1168\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 110.0073 - val_loss: 177.2583\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 109.3882 - val_loss: 180.5800\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 108.9649 - val_loss: 198.3814\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 108.4618 - val_loss: 172.6643\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 108.7211 - val_loss: 178.3009\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 33s 4ms/step - loss: 108.7643 - val_loss: 171.5973\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 108.5799 - val_loss: 177.5068\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 108.9325 - val_loss: 205.6403\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 109.1057 - val_loss: 167.2762\n",
      "Epoch 15/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 109.1434 - val_loss: 199.2914\n",
      "Epoch 16/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 109.3939 - val_loss: 186.4565\n",
      "Epoch 17/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 109.8755 - val_loss: 194.3971\n",
      "Epoch 18/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 110.1238 - val_loss: 183.9636\n",
      "Epoch 19/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 110.2782 - val_loss: 186.4957\n",
      "Epoch 20/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 110.4291 - val_loss: 184.0160\n",
      "Epoch 21/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 110.7190 - val_loss: 199.2695\n",
      "Epoch 22/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 110.6619 - val_loss: 176.0744\n",
      "Epoch 23/50\n",
      "7741/7741 [==============================] - 29s 4ms/step - loss: 111.0671 - val_loss: 175.2378\n",
      "Epoch 24/50\n",
      "7726/7741 [============================>.] - ETA: 0s - loss: 110.8616Restoring model weights from the end of the best epoch: 14.\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 110.9056 - val_loss: 217.2123\n",
      "Epoch 24: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 609.6968 - val_loss: 523.2829\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 289.2191 - val_loss: 508.6226\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 287.5623 - val_loss: 477.0097\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 286.3049 - val_loss: 510.7290\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 284.9789 - val_loss: 436.1499\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 284.5125 - val_loss: 485.0831\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 282.5385 - val_loss: 528.0023\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 281.1249 - val_loss: 501.6565\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 279.6813 - val_loss: 466.6423\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 277.9191 - val_loss: 486.3878\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 276.6148 - val_loss: 404.1077\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 274.3941 - val_loss: 477.1617\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 272.6471 - val_loss: 576.2016\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 272.4152 - val_loss: 450.9697\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 271.0648 - val_loss: 453.8461\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 270.8233 - val_loss: 441.6323\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 269.3561 - val_loss: 414.9035\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 269.9545 - val_loss: 451.7477\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 268.6170 - val_loss: 481.5043\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 268.0266 - val_loss: 519.9386\n",
      "Epoch 21/50\n",
      "3065/3084 [============================>.] - ETA: 0s - loss: 266.8746Restoring model weights from the end of the best epoch: 11.\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 267.1354 - val_loss: 413.8809\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 2s 3ms/step - loss: 235.5757 - val_loss: 13.2424\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 6.4414 - val_loss: 6.7906\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.5287 - val_loss: 4.3671\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.0005 - val_loss: 3.8590\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.7601 - val_loss: 3.1639\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4364 - val_loss: 3.1571\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4226 - val_loss: 3.9035\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.3716 - val_loss: 5.9298\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2062 - val_loss: 5.1473\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0759 - val_loss: 3.4624\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0810 - val_loss: 3.7830\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9501 - val_loss: 2.9748\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9686 - val_loss: 2.6704\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8450 - val_loss: 3.2949\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9015 - val_loss: 3.9563\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8463 - val_loss: 3.2698\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7621 - val_loss: 3.9454\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6913 - val_loss: 2.5528\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6919 - val_loss: 2.4206\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7405 - val_loss: 2.5255\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7168 - val_loss: 2.2606\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6574 - val_loss: 4.8977\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5754 - val_loss: 3.0427\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6434 - val_loss: 7.6366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6323 - val_loss: 2.2389\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5956 - val_loss: 2.3829\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5292 - val_loss: 3.9458\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5750 - val_loss: 2.5546\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5008 - val_loss: 1.9733\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5746 - val_loss: 3.6683\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5228 - val_loss: 2.0157\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5041 - val_loss: 2.3635\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6011 - val_loss: 4.1366\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5122 - val_loss: 2.6600\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4531 - val_loss: 2.3220\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5245 - val_loss: 3.2635\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4260 - val_loss: 3.2555\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3843 - val_loss: 1.9780\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4071 - val_loss: 1.9232\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4734 - val_loss: 2.0643\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4057 - val_loss: 3.1440\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4064 - val_loss: 3.3104\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3888 - val_loss: 2.3893\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3991 - val_loss: 2.2785\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4070 - val_loss: 2.5112\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3729 - val_loss: 1.8214\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3927 - val_loss: 2.0108\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3387 - val_loss: 1.9956\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3372 - val_loss: 1.8436\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3497 - val_loss: 2.0609\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 7.5066 - val_loss: 5.0207\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.5439 - val_loss: 2.6571\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.3595 - val_loss: 4.0000\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.2363 - val_loss: 2.4371\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.1388 - val_loss: 2.5295\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.0807 - val_loss: 4.9035\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.0217 - val_loss: 2.3098\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.9742 - val_loss: 2.2533\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.9511 - val_loss: 2.3192\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.9075 - val_loss: 2.1379\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8854 - val_loss: 2.2044\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8588 - val_loss: 2.1017\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8407 - val_loss: 2.0384\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8252 - val_loss: 2.6207\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8057 - val_loss: 2.0450\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7966 - val_loss: 2.1543\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7887 - val_loss: 2.6226\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7696 - val_loss: 2.0517\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7559 - val_loss: 2.0115\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7543 - val_loss: 2.6346\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7444 - val_loss: 1.9498\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7318 - val_loss: 2.2265\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7263 - val_loss: 2.1196\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7214 - val_loss: 1.9884\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7164 - val_loss: 2.2939\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7076 - val_loss: 1.9730\n",
      "Epoch 27/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7071 - val_loss: 2.0587\n",
      "Epoch 28/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6965 - val_loss: 1.9668\n",
      "Epoch 29/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6906 - val_loss: 2.0337\n",
      "Epoch 30/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6814 - val_loss: 2.3326\n",
      "Epoch 31/50\n",
      "4363/4377 [============================>.] - ETA: 0s - loss: 1.6773Restoring model weights from the end of the best epoch: 21.\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6754 - val_loss: 1.9631\n",
      "Epoch 31: early stopping\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 134.7850 - val_loss: 232.4202\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 117.5852 - val_loss: 207.9292\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 114.3216 - val_loss: 211.5134\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 113.2372 - val_loss: 188.3164\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 112.8727 - val_loss: 177.1405\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 112.5576 - val_loss: 186.6995\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 111.9343 - val_loss: 201.9093\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 111.7724 - val_loss: 210.7221\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 111.4315 - val_loss: 188.3789\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 111.3244 - val_loss: 180.5151\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 30s 4ms/step - loss: 111.2198 - val_loss: 185.8153\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 111.0599 - val_loss: 181.5506\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 32s 4ms/step - loss: 111.2387 - val_loss: 228.3595\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 110.8516 - val_loss: 178.1983\n",
      "Epoch 15/50\n",
      "7737/7741 [============================>.] - ETA: 0s - loss: 110.8999Restoring model weights from the end of the best epoch: 5.\n",
      "7741/7741 [==============================] - 31s 4ms/step - loss: 110.9179 - val_loss: 210.5561\n",
      "Epoch 15: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 504.7860 - val_loss: 520.7795\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 285.5412 - val_loss: 482.4450\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 281.1873 - val_loss: 459.2813\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 278.6797 - val_loss: 527.9251\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3084/3084 [==============================] - 9s 3ms/step - loss: 275.3446 - val_loss: 419.8677\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 273.8220 - val_loss: 444.2623\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 271.3323 - val_loss: 479.1363\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 269.9249 - val_loss: 476.3713\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 269.0880 - val_loss: 422.4248\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 268.5350 - val_loss: 420.6581\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 8s 3ms/step - loss: 268.6879 - val_loss: 389.0290\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 266.8993 - val_loss: 397.7972\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 266.9772 - val_loss: 571.8239\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 266.4159 - val_loss: 436.0771\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 265.3770 - val_loss: 442.7982\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 265.3444 - val_loss: 387.5496\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 264.3084 - val_loss: 404.4297\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 264.8438 - val_loss: 414.6082\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 264.2356 - val_loss: 469.0366\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 263.5433 - val_loss: 449.3516\n",
      "Epoch 21/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 263.1395 - val_loss: 425.2020\n",
      "Epoch 22/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 262.3345 - val_loss: 400.9264\n",
      "Epoch 23/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 261.7910 - val_loss: 477.9422\n",
      "Epoch 24/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 262.1378 - val_loss: 422.4776\n",
      "Epoch 25/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 262.1736 - val_loss: 429.8819\n",
      "Epoch 26/50\n",
      "3069/3084 [============================>.] - ETA: 0s - loss: 260.8231Restoring model weights from the end of the best epoch: 16.\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 260.7548 - val_loss: 399.3705\n",
      "Epoch 26: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 2s 4ms/step - loss: 207.6093 - val_loss: 10.3457\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 5.2508 - val_loss: 5.0170\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.8870 - val_loss: 5.2627\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4018 - val_loss: 4.3689\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2982 - val_loss: 2.7216\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0183 - val_loss: 2.9261\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9045 - val_loss: 3.1807\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7394 - val_loss: 3.9832\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7494 - val_loss: 4.5521\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6094 - val_loss: 3.8064\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6590 - val_loss: 3.4776\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5928 - val_loss: 3.8826\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4556 - val_loss: 2.2693\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4164 - val_loss: 2.1369\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3139 - val_loss: 2.5621\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4412 - val_loss: 3.7886\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3147 - val_loss: 4.6241\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3917 - val_loss: 2.5109\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3749 - val_loss: 2.7276\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4226 - val_loss: 2.2200\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2618 - val_loss: 1.8635\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3281 - val_loss: 2.5213\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2616 - val_loss: 2.1866\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2134 - val_loss: 4.2375\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3430 - val_loss: 2.0811\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2960 - val_loss: 2.1359\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1535 - val_loss: 2.3652\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0993 - val_loss: 2.1525\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.2023 - val_loss: 1.7287\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1600 - val_loss: 2.4191\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1875 - val_loss: 1.7904\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2215 - val_loss: 1.8607\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1435 - val_loss: 3.8442\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1041 - val_loss: 3.3306\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0394 - val_loss: 1.8462\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1141 - val_loss: 1.8765\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1240 - val_loss: 3.9375\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0560 - val_loss: 1.7260\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0449 - val_loss: 5.8191\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0142 - val_loss: 1.8847\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0224 - val_loss: 1.9889\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0032 - val_loss: 2.1175\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0726 - val_loss: 2.6312\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.9685 - val_loss: 1.9633\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.9672 - val_loss: 1.9270\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.9458 - val_loss: 2.3841\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0458 - val_loss: 1.7093\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.9612 - val_loss: 1.6501\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.9465 - val_loss: 1.7220\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.9045 - val_loss: 2.0671\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 7.0804 - val_loss: 3.2902\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.2447 - val_loss: 2.6940\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.0765 - val_loss: 2.8159\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.9792 - val_loss: 2.4486\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.9115 - val_loss: 2.2962\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8818 - val_loss: 2.5656\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8089 - val_loss: 2.0235\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7956 - val_loss: 2.2275\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7728 - val_loss: 2.0960\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7423 - val_loss: 1.9426\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7286 - val_loss: 2.5604\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7072 - val_loss: 2.0086\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6865 - val_loss: 1.8362\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6694 - val_loss: 2.7183\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6521 - val_loss: 1.8168\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6501 - val_loss: 1.8676\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6369 - val_loss: 2.9460\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6331 - val_loss: 1.8987\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6154 - val_loss: 2.1809\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6106 - val_loss: 1.8681\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5953 - val_loss: 1.8171\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5792 - val_loss: 1.9040\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5649 - val_loss: 1.8938\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5677 - val_loss: 1.8189\n",
      "Epoch 25/50\n",
      "4374/4377 [============================>.] - ETA: 0s - loss: 1.5596Restoring model weights from the end of the best epoch: 15.\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5599 - val_loss: 1.8792\n",
      "Epoch 25: early stopping\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 139.8644 - val_loss: 235.1244\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 113.6116 - val_loss: 200.2956\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 35s 4ms/step - loss: 112.1645 - val_loss: 230.7001\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 111.1002 - val_loss: 188.8735\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 110.7256 - val_loss: 168.8386\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 110.2160 - val_loss: 172.9168\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 109.7968 - val_loss: 189.7022\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 109.7203 - val_loss: 221.2324\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 109.3993 - val_loss: 185.1957\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 109.3512 - val_loss: 174.5545\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 109.1711 - val_loss: 180.9086\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 35s 4ms/step - loss: 109.0296 - val_loss: 166.5523\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 109.2395 - val_loss: 213.3775\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 108.9467 - val_loss: 168.3258\n",
      "Epoch 15/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 109.5349 - val_loss: 203.3698\n",
      "Epoch 16/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 109.3901 - val_loss: 189.6405\n",
      "Epoch 17/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 109.9320 - val_loss: 175.8368\n",
      "Epoch 18/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 110.3495 - val_loss: 194.7691\n",
      "Epoch 19/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 110.3611 - val_loss: 189.7576\n",
      "Epoch 20/50\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 110.6030 - val_loss: 165.4213\n",
      "Epoch 21/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 110.7524 - val_loss: 215.9827\n",
      "Epoch 22/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 111.0920 - val_loss: 182.2597\n",
      "Epoch 23/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 111.0395 - val_loss: 190.8086\n",
      "Epoch 24/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 110.8422 - val_loss: 226.9950\n",
      "Epoch 25/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 111.0306 - val_loss: 188.8207\n",
      "Epoch 26/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 110.9836 - val_loss: 166.7607\n",
      "Epoch 27/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 111.3160 - val_loss: 184.7910\n",
      "Epoch 28/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 111.5865 - val_loss: 165.8278\n",
      "Epoch 29/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 111.5977 - val_loss: 165.6073\n",
      "Epoch 30/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 111.7167 - val_loss: 164.8803\n",
      "Epoch 31/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 112.3902 - val_loss: 185.8535\n",
      "Epoch 32/50\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 112.1510 - val_loss: 170.5085\n",
      "Epoch 33/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 112.4934 - val_loss: 233.0889\n",
      "Epoch 34/50\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 113.0739 - val_loss: 194.4200\n",
      "Epoch 35/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 113.0048 - val_loss: 183.1584\n",
      "Epoch 36/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 113.0233 - val_loss: 207.4601\n",
      "Epoch 37/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 112.8966 - val_loss: 182.0623\n",
      "Epoch 38/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 113.2199 - val_loss: 178.7699\n",
      "Epoch 39/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 113.4323 - val_loss: 175.8253\n",
      "Epoch 40/50\n",
      "7736/7741 [============================>.] - ETA: 0s - loss: 113.4985Restoring model weights from the end of the best epoch: 30.\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 113.4848 - val_loss: 169.0682\n",
      "Epoch 40: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 12s 4ms/step - loss: 480.3557 - val_loss: 534.0159\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 292.1278 - val_loss: 494.3268\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 289.1585 - val_loss: 495.0854\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 287.6460 - val_loss: 546.8459\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 286.2816 - val_loss: 447.4706\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 285.3362 - val_loss: 456.1138\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 282.9036 - val_loss: 502.4678\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 279.9471 - val_loss: 570.3810\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 278.5853 - val_loss: 463.5798\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 277.0351 - val_loss: 462.3058\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 276.0372 - val_loss: 405.1635\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 273.4948 - val_loss: 428.4933\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 272.3108 - val_loss: 552.8813\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 272.5255 - val_loss: 525.7757\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 270.5089 - val_loss: 458.8776\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3084/3084 [==============================] - 9s 3ms/step - loss: 270.4311 - val_loss: 413.6768\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 269.5845 - val_loss: 398.6921\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 269.3678 - val_loss: 452.9937\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 268.1427 - val_loss: 479.8983\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 267.7920 - val_loss: 491.8240\n",
      "Epoch 21/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 267.6012 - val_loss: 402.2278\n",
      "Epoch 22/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 267.0504 - val_loss: 405.9541\n",
      "Epoch 23/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 265.7522 - val_loss: 462.6840\n",
      "Epoch 24/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 266.5170 - val_loss: 397.6158\n",
      "Epoch 25/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 266.9569 - val_loss: 516.5316\n",
      "Epoch 26/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.9055 - val_loss: 374.5840\n",
      "Epoch 27/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.3917 - val_loss: 390.7099\n",
      "Epoch 28/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.2581 - val_loss: 419.9018\n",
      "Epoch 29/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.9245 - val_loss: 442.4097\n",
      "Epoch 30/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.2126 - val_loss: 449.5355\n",
      "Epoch 31/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 264.7250 - val_loss: 437.6204\n",
      "Epoch 32/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.0620 - val_loss: 435.2802\n",
      "Epoch 33/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 264.7114 - val_loss: 395.4813\n",
      "Epoch 34/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 264.3534 - val_loss: 441.2662\n",
      "Epoch 35/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 264.3445 - val_loss: 478.8607\n",
      "Epoch 36/50\n",
      "3078/3084 [============================>.] - ETA: 0s - loss: 263.6220Restoring model weights from the end of the best epoch: 26.\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 263.9408 - val_loss: 406.0954\n",
      "Epoch 36: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 2s 4ms/step - loss: 153.3844 - val_loss: 8.0450\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 6.0206 - val_loss: 4.6847\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.9637 - val_loss: 4.7293\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.3343 - val_loss: 3.6349\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.8346 - val_loss: 4.3020\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.8390 - val_loss: 5.5440\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.6944 - val_loss: 3.6998\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 3.3536 - val_loss: 3.3928\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 3.3420 - val_loss: 3.6485\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2193 - val_loss: 3.5328\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0853 - val_loss: 4.1331\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0324 - val_loss: 3.0333\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8491 - val_loss: 3.2910\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8695 - val_loss: 2.6648\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8680 - val_loss: 3.4829\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8339 - val_loss: 2.4647\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9249 - val_loss: 3.8288\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8221 - val_loss: 2.3946\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7763 - val_loss: 3.3464\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7126 - val_loss: 4.7843\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8885 - val_loss: 2.0962\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6946 - val_loss: 2.8458\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7385 - val_loss: 2.4509\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6734 - val_loss: 3.5701\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6429 - val_loss: 2.3255\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7571 - val_loss: 3.5740\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6909 - val_loss: 2.5334\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5800 - val_loss: 2.5860\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6916 - val_loss: 7.4219\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6143 - val_loss: 2.5870\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5636 - val_loss: 2.0886\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6386 - val_loss: 2.2843\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6893 - val_loss: 2.0024\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7095 - val_loss: 4.3684\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5721 - val_loss: 2.8383\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5769 - val_loss: 2.1325\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4837 - val_loss: 2.7369\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4843 - val_loss: 1.9691\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4643 - val_loss: 2.3866\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4490 - val_loss: 1.9494\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5209 - val_loss: 1.9603\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4623 - val_loss: 2.6011\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4895 - val_loss: 3.3620\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5451 - val_loss: 2.5086\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4499 - val_loss: 4.8618\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5480 - val_loss: 1.8543\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5518 - val_loss: 3.6980\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5575 - val_loss: 2.0722\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5028 - val_loss: 2.9450\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4828 - val_loss: 4.6856\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 6.3575 - val_loss: 5.3361\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.5765 - val_loss: 2.8068\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.3830 - val_loss: 5.0478\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.2347 - val_loss: 2.4775\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.1572 - val_loss: 2.7769\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.0893 - val_loss: 2.7219\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 2.0279 - val_loss: 2.4564\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.9776 - val_loss: 2.2149\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.9414 - val_loss: 2.3990\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.9028 - val_loss: 2.2966\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8866 - val_loss: 2.3310\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8615 - val_loss: 2.0590\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8379 - val_loss: 2.0631\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8185 - val_loss: 2.6141\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8071 - val_loss: 2.1410\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7857 - val_loss: 2.4210\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7805 - val_loss: 2.4647\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7589 - val_loss: 2.0288\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7444 - val_loss: 2.1311\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7510 - val_loss: 2.6675\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7294 - val_loss: 1.9574\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7142 - val_loss: 2.4271\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7079 - val_loss: 2.2297\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6962 - val_loss: 1.9207\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6884 - val_loss: 2.2673\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6847 - val_loss: 1.8766\n",
      "Epoch 27/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6821 - val_loss: 2.0436\n",
      "Epoch 28/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6684 - val_loss: 1.8847\n",
      "Epoch 29/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6673 - val_loss: 1.9669\n",
      "Epoch 30/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6553 - val_loss: 1.9730\n",
      "Epoch 31/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6493 - val_loss: 1.8827\n",
      "Epoch 32/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6491 - val_loss: 2.0042\n",
      "Epoch 33/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6393 - val_loss: 2.2602\n",
      "Epoch 34/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6340 - val_loss: 2.2761\n",
      "Epoch 35/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6287 - val_loss: 1.8825\n",
      "Epoch 36/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6272 - val_loss: 1.8146\n",
      "Epoch 37/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6206 - val_loss: 1.9182\n",
      "Epoch 38/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6225 - val_loss: 1.9840\n",
      "Epoch 39/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6136 - val_loss: 3.0043\n",
      "Epoch 40/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6147 - val_loss: 1.9783\n",
      "Epoch 41/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6112 - val_loss: 1.8117\n",
      "Epoch 42/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5953 - val_loss: 1.8353\n",
      "Epoch 43/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5926 - val_loss: 1.9220\n",
      "Epoch 44/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5950 - val_loss: 1.8117\n",
      "Epoch 45/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5850 - val_loss: 1.9160\n",
      "Epoch 46/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5846 - val_loss: 2.0686\n",
      "Epoch 47/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5819 - val_loss: 1.8399\n",
      "Epoch 48/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5711 - val_loss: 2.1688\n",
      "Epoch 49/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5841 - val_loss: 1.8293\n",
      "Epoch 50/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5755 - val_loss: 2.2370\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 38s 4ms/step - loss: 127.8738 - val_loss: 218.6854\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 33s 4ms/step - loss: 115.8235 - val_loss: 239.3064\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 114.3104 - val_loss: 234.7704\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 113.2928 - val_loss: 187.3898\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 112.7491 - val_loss: 167.6151\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 112.1592 - val_loss: 187.0631\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 111.8306 - val_loss: 191.6516\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 111.3849 - val_loss: 216.7539\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 33s 4ms/step - loss: 111.1931 - val_loss: 179.2900\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 33s 4ms/step - loss: 111.0285 - val_loss: 173.3162\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 33s 4ms/step - loss: 111.0007 - val_loss: 176.0914\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 35s 4ms/step - loss: 110.9276 - val_loss: 171.5435\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 110.7759 - val_loss: 213.6330\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 110.4904 - val_loss: 168.8202\n",
      "Epoch 15/50\n",
      "7736/7741 [============================>.] - ETA: 0s - loss: 110.5140Restoring model weights from the end of the best epoch: 5.\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 110.5186 - val_loss: 202.5459\n",
      "Epoch 15: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 490.3449 - val_loss: 595.4462\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 290.5381 - val_loss: 425.3733\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 284.1395 - val_loss: 466.9911\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 278.1198 - val_loss: 524.8082\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 273.0684 - val_loss: 415.9371\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 270.6865 - val_loss: 414.9829\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 269.0386 - val_loss: 460.6342\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 266.9024 - val_loss: 495.1055\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 265.7863 - val_loss: 408.3822\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 264.8519 - val_loss: 387.3101\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 264.5441 - val_loss: 375.1610\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 263.1368 - val_loss: 383.2675\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 262.9867 - val_loss: 579.4741\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 263.2218 - val_loss: 451.9548\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 262.4604 - val_loss: 429.7119\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 263.5320 - val_loss: 394.5833\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 261.6788 - val_loss: 395.4471\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 263.6071 - val_loss: 448.7454\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3084/3084 [==============================] - 9s 3ms/step - loss: 261.2679 - val_loss: 463.6989\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 262.0745 - val_loss: 479.1430\n",
      "Epoch 21/50\n",
      "3072/3084 [============================>.] - ETA: 0s - loss: 261.8438Restoring model weights from the end of the best epoch: 11.\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 262.0164 - val_loss: 424.3955\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 3s 4ms/step - loss: 154.4012 - val_loss: 4.2382\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.8229 - val_loss: 3.8624\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2242 - val_loss: 2.8680\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1976 - val_loss: 2.9372\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0016 - val_loss: 3.5421\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8547 - val_loss: 2.9351\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8283 - val_loss: 4.0366\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8380 - val_loss: 4.0479\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6868 - val_loss: 3.2397\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5384 - val_loss: 2.0974\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6224 - val_loss: 3.8167\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3967 - val_loss: 4.1609\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.4485 - val_loss: 2.0205\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.3251 - val_loss: 2.0954\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4913 - val_loss: 2.2479\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4441 - val_loss: 3.6617\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3117 - val_loss: 2.2277\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3012 - val_loss: 2.3022\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2021 - val_loss: 2.5181\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4910 - val_loss: 3.8812\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2826 - val_loss: 1.8526\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2457 - val_loss: 3.0908\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1071 - val_loss: 3.0487\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2597 - val_loss: 1.9027\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2122 - val_loss: 1.9751\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1842 - val_loss: 2.8952\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0773 - val_loss: 3.5252\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2101 - val_loss: 2.8776\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1231 - val_loss: 2.1656\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0809 - val_loss: 2.0053\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0758 - val_loss: 1.6955\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0998 - val_loss: 3.2688\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0865 - val_loss: 1.7688\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0847 - val_loss: 1.7555\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0655 - val_loss: 1.9043\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 1.9813 - val_loss: 2.7624\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 1.9673 - val_loss: 1.8285\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0417 - val_loss: 1.6289\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0317 - val_loss: 1.7505\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0505 - val_loss: 1.8544\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0350 - val_loss: 2.1443\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0633 - val_loss: 3.4928\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1038 - val_loss: 1.8879\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0005 - val_loss: 2.1652\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1153 - val_loss: 2.0014\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0129 - val_loss: 1.6061\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1909 - val_loss: 1.5927\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0529 - val_loss: 1.6707\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0304 - val_loss: 2.2160\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.9526 - val_loss: 2.1312\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 5.9627 - val_loss: 2.4000\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.1495 - val_loss: 2.4959\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.0277 - val_loss: 2.6244\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.9571 - val_loss: 2.4000\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.9373 - val_loss: 2.3090\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8803 - val_loss: 4.0182\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8294 - val_loss: 1.9561\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7900 - val_loss: 2.6011\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7815 - val_loss: 1.9580\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7483 - val_loss: 1.8929\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7197 - val_loss: 2.8669\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7131 - val_loss: 2.0089\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7019 - val_loss: 1.8396\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6809 - val_loss: 3.0986\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6637 - val_loss: 1.8637\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6681 - val_loss: 1.9913\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6683 - val_loss: 3.2453\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6780 - val_loss: 1.9569\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6697 - val_loss: 1.8219\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6632 - val_loss: 2.1272\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6488 - val_loss: 1.8863\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6344 - val_loss: 2.1687\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6176 - val_loss: 2.4854\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6219 - val_loss: 1.9175\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6193 - val_loss: 2.2910\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6168 - val_loss: 1.9403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6182 - val_loss: 1.8735\n",
      "Epoch 28/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6001 - val_loss: 1.8051\n",
      "Epoch 29/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6112 - val_loss: 2.5272\n",
      "Epoch 30/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5906 - val_loss: 2.2136\n",
      "Epoch 31/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5921 - val_loss: 1.7313\n",
      "Epoch 32/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5884 - val_loss: 1.8181\n",
      "Epoch 33/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5801 - val_loss: 2.0573\n",
      "Epoch 34/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5725 - val_loss: 2.1970\n",
      "Epoch 35/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5786 - val_loss: 2.0190\n",
      "Epoch 36/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5716 - val_loss: 1.8671\n",
      "Epoch 37/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5759 - val_loss: 1.7696\n",
      "Epoch 38/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5740 - val_loss: 2.1668\n",
      "Epoch 39/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5784 - val_loss: 1.7509\n",
      "Epoch 40/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5749 - val_loss: 1.9538\n",
      "Epoch 41/50\n",
      "4375/4377 [============================>.] - ETA: 0s - loss: 1.5718Restoring model weights from the end of the best epoch: 31.\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5715 - val_loss: 1.7932\n",
      "Epoch 41: early stopping\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 42s 5ms/step - loss: 120.6825 - val_loss: 241.0628\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 111.9515 - val_loss: 188.5394\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 111.1428 - val_loss: 196.7487\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 110.5620 - val_loss: 191.2973\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 110.5274 - val_loss: 162.3295\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 110.0304 - val_loss: 165.6499\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 109.9281 - val_loss: 189.1731\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 109.3285 - val_loss: 224.8282\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 109.5759 - val_loss: 171.6304\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 109.4529 - val_loss: 186.0960\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 109.3278 - val_loss: 171.8947\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 109.4777 - val_loss: 177.4513\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 109.5462 - val_loss: 211.6175\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 109.5896 - val_loss: 169.4565\n",
      "Epoch 15/50\n",
      "7741/7741 [==============================] - ETA: 0s - loss: 110.1373Restoring model weights from the end of the best epoch: 5.\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 110.1373 - val_loss: 201.9520\n",
      "Epoch 15: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 12s 3ms/step - loss: 432.8806 - val_loss: 504.3031\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 292.9442 - val_loss: 440.8515\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 287.6288 - val_loss: 484.7096\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 283.7201 - val_loss: 550.0486\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 280.2017 - val_loss: 414.9209\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 276.6765 - val_loss: 418.3077\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 273.2822 - val_loss: 472.6149\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 271.6774 - val_loss: 465.2028\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 270.3852 - val_loss: 403.8528\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 270.1552 - val_loss: 416.1147\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 270.6276 - val_loss: 381.4439\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 269.2380 - val_loss: 417.3121\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 268.7767 - val_loss: 492.6114\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 269.1315 - val_loss: 424.7310\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 267.8590 - val_loss: 455.7937\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 268.4673 - val_loss: 388.7056\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 267.7352 - val_loss: 373.8083\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 269.2850 - val_loss: 399.0716\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 267.8546 - val_loss: 485.7473\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.2859 - val_loss: 520.4400\n",
      "Epoch 21/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.1358 - val_loss: 385.1315\n",
      "Epoch 22/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.8837 - val_loss: 392.0403\n",
      "Epoch 23/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.4193 - val_loss: 429.8759\n",
      "Epoch 24/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.6995 - val_loss: 387.3293\n",
      "Epoch 25/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.4718 - val_loss: 473.1469\n",
      "Epoch 26/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 266.6534 - val_loss: 354.9297\n",
      "Epoch 27/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 267.6585 - val_loss: 418.5389\n",
      "Epoch 28/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.3959 - val_loss: 440.4716\n",
      "Epoch 29/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.8175 - val_loss: 432.0823\n",
      "Epoch 30/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.3204 - val_loss: 474.0287\n",
      "Epoch 31/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.1868 - val_loss: 421.4077\n",
      "Epoch 32/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 268.2415 - val_loss: 424.1828\n",
      "Epoch 33/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 267.6608 - val_loss: 388.4751\n",
      "Epoch 34/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 266.3930 - val_loss: 426.8055\n",
      "Epoch 35/50\n",
      "3084/3084 [==============================] - 9s 3ms/step - loss: 266.2294 - val_loss: 482.7703\n",
      "Epoch 36/50\n",
      "3084/3084 [==============================] - ETA: 0s - loss: 265.3377Restoring model weights from the end of the best epoch: 26.\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.3377 - val_loss: 398.6599\n",
      "Epoch 36: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 3s 4ms/step - loss: 115.8795 - val_loss: 6.5500\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.9911 - val_loss: 4.6300\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.4490 - val_loss: 4.8195\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.3706 - val_loss: 6.2808\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.8138 - val_loss: 3.0884\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.6992 - val_loss: 5.3450\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4225 - val_loss: 3.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4258 - val_loss: 6.4402\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2998 - val_loss: 2.8044\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4585 - val_loss: 8.8378\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1455 - val_loss: 5.9156\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0670 - val_loss: 3.7807\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9474 - val_loss: 2.5135\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0811 - val_loss: 3.7778\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0325 - val_loss: 2.2645\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8289 - val_loss: 3.9557\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7889 - val_loss: 5.9639\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8013 - val_loss: 2.4241\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.7040 - val_loss: 2.6335\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9567 - val_loss: 2.0769\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6693 - val_loss: 3.5977\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6752 - val_loss: 3.5819\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5109 - val_loss: 4.7149\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4646 - val_loss: 4.5486\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.6882 - val_loss: 2.2213\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5826 - val_loss: 4.7580\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5830 - val_loss: 2.6836\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4920 - val_loss: 2.2274\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3801 - val_loss: 5.8822\n",
      "Epoch 30/50\n",
      "265/280 [===========================>..] - ETA: 0s - loss: 2.4851Restoring model weights from the end of the best epoch: 20.\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4633 - val_loss: 3.9730\n",
      "Epoch 30: early stopping\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 16s 3ms/step - loss: 6.0595 - val_loss: 2.8057\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.4638 - val_loss: 2.6892\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 2.2574 - val_loss: 3.7731\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 2.1639 - val_loss: 2.5193\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 2.1157 - val_loss: 2.7063\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 2.0540 - val_loss: 4.8097\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.9902 - val_loss: 2.4517\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.9695 - val_loss: 2.5734\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.9470 - val_loss: 2.1092\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.9171 - val_loss: 2.1877\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.9040 - val_loss: 2.3788\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8756 - val_loss: 2.0037\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8476 - val_loss: 1.9764\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.8264 - val_loss: 3.0494\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8056 - val_loss: 2.0884\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7941 - val_loss: 2.0331\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7896 - val_loss: 2.7264\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7846 - val_loss: 2.0306\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7532 - val_loss: 2.0487\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7589 - val_loss: 2.8053\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.7524 - val_loss: 1.9470\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7289 - val_loss: 2.3857\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7373 - val_loss: 2.1874\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7258 - val_loss: 2.1946\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7108 - val_loss: 2.0899\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7091 - val_loss: 2.0284\n",
      "Epoch 27/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7051 - val_loss: 2.0187\n",
      "Epoch 28/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6853 - val_loss: 1.9000\n",
      "Epoch 29/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6832 - val_loss: 1.9719\n",
      "Epoch 30/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6801 - val_loss: 2.0426\n",
      "Epoch 31/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6721 - val_loss: 1.9464\n",
      "Epoch 32/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6635 - val_loss: 1.9432\n",
      "Epoch 33/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6655 - val_loss: 2.5980\n",
      "Epoch 34/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6580 - val_loss: 2.4278\n",
      "Epoch 35/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6548 - val_loss: 1.8775\n",
      "Epoch 36/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6423 - val_loss: 1.8325\n",
      "Epoch 37/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6391 - val_loss: 1.8489\n",
      "Epoch 38/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6389 - val_loss: 2.0885\n",
      "Epoch 39/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6492 - val_loss: 3.2649\n",
      "Epoch 40/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6291 - val_loss: 2.0739\n",
      "Epoch 41/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6283 - val_loss: 1.9769\n",
      "Epoch 42/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6155 - val_loss: 1.8548\n",
      "Epoch 43/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6163 - val_loss: 1.9817\n",
      "Epoch 44/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6196 - val_loss: 1.8050\n",
      "Epoch 45/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6131 - val_loss: 1.8126\n",
      "Epoch 46/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6117 - val_loss: 1.9761\n",
      "Epoch 47/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6043 - val_loss: 1.8165\n",
      "Epoch 48/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5898 - val_loss: 2.4623\n",
      "Epoch 49/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6016 - val_loss: 1.8694\n",
      "Epoch 50/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5966 - val_loss: 2.5072\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 126.4747 - val_loss: 236.8983\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 115.0502 - val_loss: 199.5592\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 114.4084 - val_loss: 230.9528\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 114.3646 - val_loss: 196.8415\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 114.5731 - val_loss: 172.4605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 114.6599 - val_loss: 174.9043\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 114.8338 - val_loss: 191.1480\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 114.1705 - val_loss: 215.3005\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 113.4838 - val_loss: 176.1297\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 112.9242 - val_loss: 183.8684\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 112.9160 - val_loss: 178.7132\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 112.9216 - val_loss: 175.5818\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 112.8839 - val_loss: 209.7998\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 112.4990 - val_loss: 170.4759\n",
      "Epoch 15/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 112.5395 - val_loss: 207.7768\n",
      "Epoch 16/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 112.2034 - val_loss: 200.2720\n",
      "Epoch 17/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 112.4002 - val_loss: 181.9484\n",
      "Epoch 18/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 112.2851 - val_loss: 202.7471\n",
      "Epoch 19/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 112.1352 - val_loss: 187.0655\n",
      "Epoch 20/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 112.4171 - val_loss: 169.1391\n",
      "Epoch 21/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 112.5294 - val_loss: 216.7121\n",
      "Epoch 22/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 112.7844 - val_loss: 182.7742\n",
      "Epoch 23/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 112.9124 - val_loss: 190.9752\n",
      "Epoch 24/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 112.7371 - val_loss: 219.2253\n",
      "Epoch 25/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 112.7189 - val_loss: 181.3206\n",
      "Epoch 26/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 112.5594 - val_loss: 178.3866\n",
      "Epoch 27/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 112.8366 - val_loss: 181.1878\n",
      "Epoch 28/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 112.6888 - val_loss: 170.5795\n",
      "Epoch 29/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 112.4754 - val_loss: 169.3731\n",
      "Epoch 30/50\n",
      "7741/7741 [==============================] - ETA: 0s - loss: 112.4165Restoring model weights from the end of the best epoch: 20.\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 112.4165 - val_loss: 171.7504\n",
      "Epoch 30: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 12s 3ms/step - loss: 438.5125 - val_loss: 394.7878\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 287.0887 - val_loss: 404.3561\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 277.2222 - val_loss: 430.7593\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 275.6267 - val_loss: 549.2891\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 274.1938 - val_loss: 461.6748\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 270.8601 - val_loss: 416.0871\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 269.4554 - val_loss: 447.0133\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 267.0171 - val_loss: 529.2610\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.8618 - val_loss: 391.5238\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 263.9456 - val_loss: 384.3891\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 264.6428 - val_loss: 363.1104\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 263.0384 - val_loss: 394.4486\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 262.7600 - val_loss: 551.1871\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 262.6515 - val_loss: 443.7974\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 261.9048 - val_loss: 408.8404\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 262.6609 - val_loss: 405.7953\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 260.8693 - val_loss: 381.5277\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 263.4624 - val_loss: 438.4136\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 261.5988 - val_loss: 475.6017\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 262.6579 - val_loss: 477.5316\n",
      "Epoch 21/50\n",
      "3076/3084 [============================>.] - ETA: 0s - loss: 262.3601Restoring model weights from the end of the best epoch: 11.\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 262.4907 - val_loss: 390.1210\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 3s 4ms/step - loss: 141.8649 - val_loss: 9.7552\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.9900 - val_loss: 2.9256\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 3.4054 - val_loss: 2.7060\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.2539 - val_loss: 3.3030\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 3.0781 - val_loss: 2.3501\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.8788 - val_loss: 2.3880\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.9358 - val_loss: 6.5051\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.8503 - val_loss: 2.1688\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.7520 - val_loss: 4.2653\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.6904 - val_loss: 2.1755\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.5811 - val_loss: 3.0428\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.4274 - val_loss: 4.6779\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.4840 - val_loss: 2.5971\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.4836 - val_loss: 1.9312\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.3246 - val_loss: 1.9554\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.2982 - val_loss: 4.9524\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.4570 - val_loss: 2.7557\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.3234 - val_loss: 2.1810\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.3550 - val_loss: 1.8631\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.4679 - val_loss: 2.0229\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.4276 - val_loss: 2.0186\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.2869 - val_loss: 3.0493\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.3559 - val_loss: 2.0396\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.1699 - val_loss: 2.0826\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2691 - val_loss: 1.7449\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.3071 - val_loss: 5.0297\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.2471 - val_loss: 2.3370\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.1233 - val_loss: 2.2282\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.2005 - val_loss: 1.7346\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1894 - val_loss: 1.6092\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2133 - val_loss: 1.6542\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1004 - val_loss: 2.6394\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.0090 - val_loss: 1.6687\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.0269 - val_loss: 2.0119\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1463 - val_loss: 1.8718\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0386 - val_loss: 1.9808\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0907 - val_loss: 3.1862\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 1.9251 - val_loss: 3.2541\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0220 - val_loss: 2.0186\n",
      "Epoch 40/50\n",
      "265/280 [===========================>..] - ETA: 0s - loss: 1.9079Restoring model weights from the end of the best epoch: 30.\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.9354 - val_loss: 1.6131\n",
      "Epoch 40: early stopping\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 16s 3ms/step - loss: 5.2824 - val_loss: 2.6823\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 2.1988 - val_loss: 2.4052\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 2.0314 - val_loss: 2.8630\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.9549 - val_loss: 2.3862\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8876 - val_loss: 2.2686\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8486 - val_loss: 3.8327\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7979 - val_loss: 2.0830\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7926 - val_loss: 2.6418\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7708 - val_loss: 2.1060\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7452 - val_loss: 1.8325\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7297 - val_loss: 2.1933\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7188 - val_loss: 2.0629\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6980 - val_loss: 1.8834\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6765 - val_loss: 3.0231\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6605 - val_loss: 1.9896\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6713 - val_loss: 2.2339\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6621 - val_loss: 4.0179\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6609 - val_loss: 1.8670\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6470 - val_loss: 1.7962\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6357 - val_loss: 2.5598\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6279 - val_loss: 1.8849\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6175 - val_loss: 1.9975\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5998 - val_loss: 2.7067\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6178 - val_loss: 1.8650\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6023 - val_loss: 1.8681\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5960 - val_loss: 1.8668\n",
      "Epoch 27/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5976 - val_loss: 1.9757\n",
      "Epoch 28/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5834 - val_loss: 1.7611\n",
      "Epoch 29/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5820 - val_loss: 1.9482\n",
      "Epoch 30/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5670 - val_loss: 1.8688\n",
      "Epoch 31/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5736 - val_loss: 1.9389\n",
      "Epoch 32/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5740 - val_loss: 1.7577\n",
      "Epoch 33/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5642 - val_loss: 2.1737\n",
      "Epoch 34/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5551 - val_loss: 1.9240\n",
      "Epoch 35/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5628 - val_loss: 1.8484\n",
      "Epoch 36/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5561 - val_loss: 1.7310\n",
      "Epoch 37/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5560 - val_loss: 1.9442\n",
      "Epoch 38/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5512 - val_loss: 1.9435\n",
      "Epoch 39/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5558 - val_loss: 1.7175\n",
      "Epoch 40/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5498 - val_loss: 2.0335\n",
      "Epoch 41/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5564 - val_loss: 1.7424\n",
      "Epoch 42/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5360 - val_loss: 1.7129\n",
      "Epoch 43/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5418 - val_loss: 1.7280\n",
      "Epoch 44/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5284 - val_loss: 1.6699\n",
      "Epoch 45/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5294 - val_loss: 1.9736\n",
      "Epoch 46/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5200 - val_loss: 1.7761\n",
      "Epoch 47/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5213 - val_loss: 1.7558\n",
      "Epoch 48/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.5150 - val_loss: 2.0288\n",
      "Epoch 49/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.5225 - val_loss: 1.7478\n",
      "Epoch 50/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5165 - val_loss: 3.5158\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 44s 5ms/step - loss: 122.5906 - val_loss: 220.3809\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 112.2323 - val_loss: 202.5539\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 112.3411 - val_loss: 217.2633\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 42s 5ms/step - loss: 112.2310 - val_loss: 183.7903\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 42s 5ms/step - loss: 113.7516 - val_loss: 180.9603\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 115.2779 - val_loss: 196.0390\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 116.5581 - val_loss: 188.1433\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 118.3437 - val_loss: 245.8216\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 121.2079 - val_loss: 183.6467\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 42s 5ms/step - loss: 124.1130 - val_loss: 176.9223\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 42s 5ms/step - loss: 126.4161 - val_loss: 284.6856\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 40s 5ms/step - loss: 130.2410 - val_loss: 283.4555\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 131.4349 - val_loss: 288.0818\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 131.2458 - val_loss: 194.0896\n",
      "Epoch 15/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 129.5713 - val_loss: 231.6972\n",
      "Epoch 16/50\n",
      "7741/7741 [==============================] - 42s 5ms/step - loss: 130.0754 - val_loss: 230.0381\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7741/7741 [==============================] - 42s 5ms/step - loss: 129.9300 - val_loss: 268.5542\n",
      "Epoch 18/50\n",
      "7741/7741 [==============================] - 40s 5ms/step - loss: 130.8477 - val_loss: 216.9498\n",
      "Epoch 19/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 130.8915 - val_loss: 202.0900\n",
      "Epoch 20/50\n",
      "7736/7741 [============================>.] - ETA: 0s - loss: 127.4227Restoring model weights from the end of the best epoch: 10.\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 127.4048 - val_loss: 221.9904\n",
      "Epoch 20: early stopping\n",
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 12s 3ms/step - loss: 416.5900 - val_loss: 452.9714\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 294.8484 - val_loss: 433.3459\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 289.3914 - val_loss: 494.0032\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 283.9090 - val_loss: 580.5308\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 276.9619 - val_loss: 421.8798\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 274.0915 - val_loss: 401.5028\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 272.1714 - val_loss: 468.4981\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 271.4730 - val_loss: 490.7142\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 270.6697 - val_loss: 390.5168\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 270.3459 - val_loss: 406.9457\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 270.5201 - val_loss: 380.2481\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 268.7141 - val_loss: 383.1506\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 268.1501 - val_loss: 467.9000\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 268.2188 - val_loss: 408.9703\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 267.3972 - val_loss: 449.2401\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 267.5960 - val_loss: 427.7799\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 266.3534 - val_loss: 374.1854\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 266.7086 - val_loss: 396.1294\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.6177 - val_loss: 440.7563\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.8180 - val_loss: 494.1502\n",
      "Epoch 21/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 265.1873 - val_loss: 384.1637\n",
      "Epoch 22/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 264.7416 - val_loss: 373.8835\n",
      "Epoch 23/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 263.4881 - val_loss: 423.9792\n",
      "Epoch 24/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 264.1188 - val_loss: 371.9035\n",
      "Epoch 25/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 264.2990 - val_loss: 463.1995\n",
      "Epoch 26/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 263.3160 - val_loss: 342.1361\n",
      "Epoch 27/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 263.2363 - val_loss: 381.2784\n",
      "Epoch 28/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 263.6785 - val_loss: 421.0653\n",
      "Epoch 29/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 264.2076 - val_loss: 436.7021\n",
      "Epoch 30/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 264.3709 - val_loss: 465.9861\n",
      "Epoch 31/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 263.0594 - val_loss: 423.4697\n",
      "Epoch 32/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 263.6581 - val_loss: 404.3033\n",
      "Epoch 33/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 263.4267 - val_loss: 373.3829\n",
      "Epoch 34/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 262.3080 - val_loss: 419.0400\n",
      "Epoch 35/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 263.0561 - val_loss: 516.0226\n",
      "Epoch 36/50\n",
      "3073/3084 [============================>.] - ETA: 0s - loss: 262.5950Restoring model weights from the end of the best epoch: 26.\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 262.7980 - val_loss: 401.7809\n",
      "Epoch 36: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 3s 4ms/step - loss: 99.2276 - val_loss: 5.5934\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 5.9019 - val_loss: 5.6542\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 5.1577 - val_loss: 6.8256\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.8272 - val_loss: 5.5088\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.4382 - val_loss: 7.1785\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 4.1970 - val_loss: 4.5803\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 3.9199 - val_loss: 6.5624\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 3.6470 - val_loss: 4.7155\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 3.3636 - val_loss: 2.5378\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4659 - val_loss: 3.3764\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1059 - val_loss: 5.5975\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9831 - val_loss: 3.3234\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9504 - val_loss: 2.6677\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.9965 - val_loss: 2.8042\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.9628 - val_loss: 3.1428\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.9261 - val_loss: 3.6776\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8263 - val_loss: 2.6156\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.0626\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7471 - val_loss: 2.7039\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7347 - val_loss: 2.2916\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5824 - val_loss: 2.1961\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.6481 - val_loss: 4.7268\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.5921 - val_loss: 3.7788\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4820 - val_loss: 2.5702\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5865 - val_loss: 2.7190\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5312 - val_loss: 5.7677\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4491 - val_loss: 2.5991\n",
      "Epoch 28/50\n",
      "275/280 [============================>.] - ETA: 0s - loss: 2.4667Restoring model weights from the end of the best epoch: 18.\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4586 - val_loss: 2.9027\n",
      "Epoch 28: early stopping\n",
      "Epoch 1/50\n",
      "4377/4377 [==============================] - 17s 3ms/step - loss: 5.1537 - val_loss: 7.2142\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 2.5289 - val_loss: 2.6784\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 2.3090 - val_loss: 3.7391\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 2.1587 - val_loss: 2.6141\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 2.0842 - val_loss: 2.3042\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 2.0533 - val_loss: 3.0650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 15s 4ms/step - loss: 2.0013 - val_loss: 2.2353\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.9836 - val_loss: 2.3234\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.9719 - val_loss: 2.1066\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.9440 - val_loss: 2.5412\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.9293 - val_loss: 2.0912\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.9114 - val_loss: 2.0285\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.8749 - val_loss: 2.0406\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8508 - val_loss: 2.5820\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.8410 - val_loss: 2.3174\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.8294 - val_loss: 2.1534\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.8183 - val_loss: 3.0722\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.8069 - val_loss: 2.0027\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7812 - val_loss: 2.3415\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7850 - val_loss: 3.0751\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7739 - val_loss: 2.1765\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7571 - val_loss: 2.2221\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.7447 - val_loss: 2.3518\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.7359 - val_loss: 2.1785\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 15s 4ms/step - loss: 1.7286 - val_loss: 1.9808\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.7122 - val_loss: 1.9968\n",
      "Epoch 27/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7073 - val_loss: 2.0216\n",
      "Epoch 28/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.7061 - val_loss: 1.9270\n",
      "Epoch 29/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.7024 - val_loss: 1.9953\n",
      "Epoch 30/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.7012 - val_loss: 2.4558\n",
      "Epoch 31/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6975 - val_loss: 1.9025\n",
      "Epoch 32/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6889 - val_loss: 1.9886\n",
      "Epoch 33/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6829 - val_loss: 2.4217\n",
      "Epoch 34/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6729 - val_loss: 2.9845\n",
      "Epoch 35/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6619 - val_loss: 1.8754\n",
      "Epoch 36/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6527 - val_loss: 1.8776\n",
      "Epoch 37/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6538 - val_loss: 1.9850\n",
      "Epoch 38/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6513 - val_loss: 2.0780\n",
      "Epoch 39/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6509 - val_loss: 2.5028\n",
      "Epoch 40/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6390 - val_loss: 1.9741\n",
      "Epoch 41/50\n",
      "4377/4377 [==============================] - 15s 4ms/step - loss: 1.6381 - val_loss: 1.9124\n",
      "Epoch 42/50\n",
      "4377/4377 [==============================] - 15s 4ms/step - loss: 1.6189 - val_loss: 1.8406\n",
      "Epoch 43/50\n",
      "4377/4377 [==============================] - 15s 4ms/step - loss: 1.6225 - val_loss: 2.0729\n",
      "Epoch 44/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.6268 - val_loss: 1.8214\n",
      "Epoch 45/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6146 - val_loss: 1.8616\n",
      "Epoch 46/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6116 - val_loss: 1.9764\n",
      "Epoch 47/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6098 - val_loss: 1.8332\n",
      "Epoch 48/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5931 - val_loss: 2.4165\n",
      "Epoch 49/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6030 - val_loss: 1.9225\n",
      "Epoch 50/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5937 - val_loss: 2.1793\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 46s 5ms/step - loss: 129.4536 - val_loss: 255.0552\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 44s 6ms/step - loss: 116.9753 - val_loss: 227.5209\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 43s 6ms/step - loss: 117.7487 - val_loss: 251.0543\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 43s 6ms/step - loss: 118.1460 - val_loss: 226.2056\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 119.3258 - val_loss: 181.2511\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 121.3513 - val_loss: 174.8312\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 123.3736 - val_loss: 195.6720\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 43s 6ms/step - loss: 124.0008 - val_loss: 253.2138\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 43s 6ms/step - loss: 126.6582 - val_loss: 199.4843\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 42s 5ms/step - loss: 129.9556 - val_loss: 202.4128\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 133.0310 - val_loss: 189.6078\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 136.0148 - val_loss: 195.4829\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 42s 5ms/step - loss: 138.3838 - val_loss: 351.3369\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 44s 6ms/step - loss: 137.4284 - val_loss: 325.4406\n",
      "Epoch 15/50\n",
      "7741/7741 [==============================] - 43s 6ms/step - loss: 137.9794 - val_loss: 225.2279\n",
      "Epoch 16/50\n",
      "7732/7741 [============================>.] - ETA: 0s - loss: 135.2365Restoring model weights from the end of the best epoch: 6.\n",
      "7741/7741 [==============================] - 41s 5ms/step - loss: 135.1907 - val_loss: 233.7381\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Possible hyperparameters\n",
    "neurons_options = [[64], [128], [64, 64], [128, 128], [64, 128, 64], [128, 128, 128]]\n",
    "activation_options = ['relu', 'elu']\n",
    "num_layers_options = [1, 2, 3]\n",
    "learning_rate = 0.001\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_TSLA, X_test_TSLA = df_TSLA_train[features], df_TSLA_test[features]\n",
    "y_train_TSLA, y_test_TSLA = df_TSLA_train[target], df_TSLA_test[target]\n",
    "\n",
    "X_train_TSLA_scaled = scaler.fit_transform(X_train_TSLA)\n",
    "X_test_TSLA_scaled = scaler.transform(X_test_TSLA)\n",
    "\n",
    "# Keep track of experiments\n",
    "experiment_log = []\n",
    "\n",
    "input_shape = (len(features),)  # Expects the number of features\n",
    "\n",
    "# Hyperparameter tuning loop\n",
    "for neurons_per_layer in neurons_options:\n",
    "    for activation in activation_options:\n",
    "        num_layers = len(neurons_per_layer)\n",
    "        # Create sub-models for each moneyness category\n",
    "        module_itm = create_module(input_shape, neurons_per_layer, num_layers, activation)\n",
    "        module_atm = create_module(input_shape, neurons_per_layer, num_layers, activation)\n",
    "        module_otm = create_module(input_shape, neurons_per_layer, num_layers, activation)\n",
    "\n",
    "        # Compile each module\n",
    "        module_itm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "        module_atm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "        module_otm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "        \n",
    "        # Train each module on its respective subset\n",
    "        history_itm = module_itm.fit(X_itm_TSLA_scaled, y_itm_TSLA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "        history_atm = module_atm.fit(X_atm_TSLA_scaled, y_atm_TSLA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "        history_otm = module_otm.fit(X_otm_TSLA_scaled, y_otm_TSLA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "        \n",
    "        # Get the best validation loss from each module training history\n",
    "        val_loss_itm = min(history_itm.history['val_loss'])\n",
    "        val_loss_atm = min(history_atm.history['val_loss'])\n",
    "        val_loss_otm = min(history_otm.history['val_loss'])\n",
    "\n",
    "        # Define the combined model\n",
    "        input_layer = Input(shape=input_shape)\n",
    "        output_itm = module_itm(input_layer)\n",
    "        output_atm = module_atm(input_layer)\n",
    "        output_otm = module_otm(input_layer)\n",
    "\n",
    "        combined_output = Concatenate()([output_itm, output_atm, output_otm])\n",
    "        final_output = Dense(1, activation='linear')(combined_output)\n",
    "        combined_model = Model(inputs=input_layer, outputs=final_output)\n",
    "\n",
    "        # Compile the combined model\n",
    "        combined_model.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0), loss='mean_squared_error')\n",
    "\n",
    "        # Fit the combined model to the full dataset (or a representative training set)\n",
    "        history_combined = combined_model.fit(X_train_TSLA_scaled, y_train_TSLA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "        \n",
    "        # Get the best validation loss from the combined model training history\n",
    "        val_loss_combined = min(history_combined.history['val_loss'])\n",
    "\n",
    "        # Log the experiment results\n",
    "        experiment_log.append({\n",
    "            'neurons_per_layer': neurons_per_layer,\n",
    "            'num_layers': num_layers,\n",
    "            'activation': activation,\n",
    "            'learning_rate': learning_rate,\n",
    "            'val_loss_itm': val_loss_itm,\n",
    "            'val_loss_atm': val_loss_atm,\n",
    "            'val_loss_otm': val_loss_otm,\n",
    "            'val_loss_combined': val_loss_combined\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd1aee",
   "metadata": {},
   "source": [
    "## Best Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d2c6aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best experiment: {'neurons_per_layer': [128, 128, 128], 'num_layers': 3, 'activation': 'elu', 'learning_rate': 0.001, 'val_loss_itm': 342.1361389160156, 'val_loss_atm': 2.062634229660034, 'val_loss_otm': 1.8214024305343628, 'val_loss_combined': 174.83120727539062}\n"
     ]
    }
   ],
   "source": [
    "# Find the best experiment\n",
    "best_experiment_2 = min(experiment_log, key=lambda x: x['val_loss_itm'])\n",
    "print(\"Best experiment:\", best_experiment_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa13dd",
   "metadata": {},
   "source": [
    "### The best model architecture for in-the-money sub module is 3 layers of 128 neurons each with an activation function of elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ea9b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best experiment: {'neurons_per_layer': [64, 128, 64], 'num_layers': 3, 'activation': 'relu', 'learning_rate': 0.001, 'val_loss_itm': 375.1610107421875, 'val_loss_atm': 1.592731237411499, 'val_loss_otm': 1.7313268184661865, 'val_loss_combined': 162.32948303222656}\n"
     ]
    }
   ],
   "source": [
    "# Find the best experiment\n",
    "best_experiment_3 = min(experiment_log, key=lambda x: x['val_loss_atm'])\n",
    "print(\"Best experiment:\", best_experiment_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7343e624",
   "metadata": {},
   "source": [
    "### The best model architecture for at-the-money sub module is 3 layers of 64, 128 and 64 neurons each with an activation function of relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a0e0c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best experiment: {'neurons_per_layer': [128], 'num_layers': 1, 'activation': 'relu', 'learning_rate': 0.001, 'val_loss_itm': 461.9157409667969, 'val_loss_atm': 1.6976430416107178, 'val_loss_otm': 1.6193618774414062, 'val_loss_combined': 170.81753540039062}\n"
     ]
    }
   ],
   "source": [
    "# Find the best experiment\n",
    "best_experiment_4 = min(experiment_log, key=lambda x: x['val_loss_otm'])\n",
    "print(\"Best experiment:\", best_experiment_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b37b7",
   "metadata": {},
   "source": [
    "### The best model architecture for on-the-money sub module is 1 layers of 128 neurons with an activation function of relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f984317",
   "metadata": {},
   "source": [
    "## Train Model for TSLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e04b5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3084/3084 [==============================] - 15s 4ms/step - loss: 404.2119 - val_loss: 406.5200\n",
      "Epoch 2/50\n",
      "3084/3084 [==============================] - 12s 4ms/step - loss: 296.0472 - val_loss: 430.2823\n",
      "Epoch 3/50\n",
      "3084/3084 [==============================] - 12s 4ms/step - loss: 287.8480 - val_loss: 472.4330\n",
      "Epoch 4/50\n",
      "3084/3084 [==============================] - 12s 4ms/step - loss: 280.0151 - val_loss: 470.1441\n",
      "Epoch 5/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 276.5870 - val_loss: 394.1416\n",
      "Epoch 6/50\n",
      "3084/3084 [==============================] - 13s 4ms/step - loss: 274.0851 - val_loss: 408.4473\n",
      "Epoch 7/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 272.2537 - val_loss: 472.3474\n",
      "Epoch 8/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 271.5795 - val_loss: 502.2684\n",
      "Epoch 9/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 270.8961 - val_loss: 398.0674\n",
      "Epoch 10/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 270.9229 - val_loss: 390.5600\n",
      "Epoch 11/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 270.8499 - val_loss: 379.9943\n",
      "Epoch 12/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 269.1947 - val_loss: 408.1506\n",
      "Epoch 13/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 268.4348 - val_loss: 480.0779\n",
      "Epoch 14/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 269.1937 - val_loss: 403.7811\n",
      "Epoch 15/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 268.0336 - val_loss: 455.0977\n",
      "Epoch 16/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 268.6012 - val_loss: 403.9932\n",
      "Epoch 17/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 267.2031 - val_loss: 368.6811\n",
      "Epoch 18/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 267.2987 - val_loss: 400.8664\n",
      "Epoch 19/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 266.0309 - val_loss: 459.7351\n",
      "Epoch 20/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 266.2838 - val_loss: 501.6623\n",
      "Epoch 21/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 265.8691 - val_loss: 381.9675\n",
      "Epoch 22/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 265.8561 - val_loss: 378.7239\n",
      "Epoch 23/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 264.5405 - val_loss: 407.3644\n",
      "Epoch 24/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 265.3373 - val_loss: 366.6562\n",
      "Epoch 25/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 265.3846 - val_loss: 480.7099\n",
      "Epoch 26/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 264.1828 - val_loss: 347.3717\n",
      "Epoch 27/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 264.8239 - val_loss: 396.7784\n",
      "Epoch 28/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 264.8432 - val_loss: 418.3005\n",
      "Epoch 29/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 265.8471 - val_loss: 418.2928\n",
      "Epoch 30/50\n",
      "3084/3084 [==============================] - 10s 3ms/step - loss: 266.2462 - val_loss: 461.6205\n",
      "Epoch 31/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 265.4338 - val_loss: 418.4135\n",
      "Epoch 32/50\n",
      "3084/3084 [==============================] - 11s 4ms/step - loss: 266.2674 - val_loss: 423.1474\n",
      "Epoch 33/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 266.0736 - val_loss: 375.6715\n",
      "Epoch 34/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 265.2027 - val_loss: 428.0647\n",
      "Epoch 35/50\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 265.5540 - val_loss: 528.0034\n",
      "Epoch 36/50\n",
      "3077/3084 [============================>.] - ETA: 0s - loss: 264.7388Restoring model weights from the end of the best epoch: 26.\n",
      "3084/3084 [==============================] - 11s 3ms/step - loss: 265.0585 - val_loss: 394.8592\n",
      "Epoch 36: early stopping\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 3s 4ms/step - loss: 166.6851 - val_loss: 4.8811\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.0802 - val_loss: 4.3142\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.4389 - val_loss: 4.0447\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.1427 - val_loss: 3.0385\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 3.0678 - val_loss: 3.2161\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8739 - val_loss: 4.9094\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.8289 - val_loss: 3.2938\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7744 - val_loss: 3.4744\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.7308 - val_loss: 2.6272\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5215 - val_loss: 3.6171\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.5929 - val_loss: 2.2367\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4975 - val_loss: 2.9754\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4339 - val_loss: 2.0185\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.4528 - val_loss: 2.0172\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3288 - val_loss: 2.2626\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.3529 - val_loss: 3.1363\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3178 - val_loss: 3.0715\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4864 - val_loss: 2.0743\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3295 - val_loss: 1.8336\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.4251 - val_loss: 2.8239\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.3018 - val_loss: 1.8835\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1801 - val_loss: 2.9877\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1579 - val_loss: 2.0596\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1270 - val_loss: 3.6452\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.1292 - val_loss: 2.2707\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.1212 - val_loss: 3.4320\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.1989 - val_loss: 1.7749\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0330 - val_loss: 3.0173\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2146 - val_loss: 1.7018\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.1034 - val_loss: 2.0290\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.2236 - val_loss: 1.7675\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 2.1552 - val_loss: 1.9063\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0827 - val_loss: 1.8441\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1025 - val_loss: 1.8013\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0540 - val_loss: 1.7170\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.1052 - val_loss: 2.0463\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0184 - val_loss: 1.8067\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.0250 - val_loss: 1.7177\n",
      "Epoch 39/50\n",
      "272/280 [============================>.] - ETA: 0s - loss: 1.9182Restoring model weights from the end of the best epoch: 29.\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.9111 - val_loss: 1.9205\n",
      "Epoch 39: early stopping\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4377/4377 [==============================] - 14s 3ms/step - loss: 14.4734 - val_loss: 3.2245\n",
      "Epoch 2/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.5128 - val_loss: 2.7899\n",
      "Epoch 3/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.1888 - val_loss: 3.1088\n",
      "Epoch 4/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 2.0376 - val_loss: 2.3036\n",
      "Epoch 5/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.9425 - val_loss: 2.6356\n",
      "Epoch 6/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8925 - val_loss: 2.6797\n",
      "Epoch 7/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8452 - val_loss: 2.1468\n",
      "Epoch 8/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.8066 - val_loss: 2.0962\n",
      "Epoch 9/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.7869 - val_loss: 2.0578\n",
      "Epoch 10/50\n",
      "4377/4377 [==============================] - 11s 3ms/step - loss: 1.7503 - val_loss: 2.1999\n",
      "Epoch 11/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7398 - val_loss: 2.3426\n",
      "Epoch 12/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.7195 - val_loss: 2.0477\n",
      "Epoch 13/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6988 - val_loss: 2.2593\n",
      "Epoch 14/50\n",
      "4377/4377 [==============================] - 15s 3ms/step - loss: 1.6769 - val_loss: 1.9313\n",
      "Epoch 15/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.6753 - val_loss: 2.0287\n",
      "Epoch 16/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.6674 - val_loss: 2.0424\n",
      "Epoch 17/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6522 - val_loss: 2.2229\n",
      "Epoch 18/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6553 - val_loss: 1.9649\n",
      "Epoch 19/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6342 - val_loss: 1.9625\n",
      "Epoch 20/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6307 - val_loss: 1.9394\n",
      "Epoch 21/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6277 - val_loss: 1.8862\n",
      "Epoch 22/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6231 - val_loss: 1.9054\n",
      "Epoch 23/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.6140 - val_loss: 2.2956\n",
      "Epoch 24/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.6027 - val_loss: 1.8685\n",
      "Epoch 25/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.5991 - val_loss: 1.7891\n",
      "Epoch 26/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5968 - val_loss: 1.9083\n",
      "Epoch 27/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5890 - val_loss: 2.1561\n",
      "Epoch 28/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5812 - val_loss: 1.8850\n",
      "Epoch 29/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5824 - val_loss: 1.7864\n",
      "Epoch 30/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5834 - val_loss: 2.4378\n",
      "Epoch 31/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5711 - val_loss: 1.8371\n",
      "Epoch 32/50\n",
      "4377/4377 [==============================] - 14s 3ms/step - loss: 1.5683 - val_loss: 2.0876\n",
      "Epoch 33/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5585 - val_loss: 2.0237\n",
      "Epoch 34/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5552 - val_loss: 1.8624\n",
      "Epoch 35/50\n",
      "4377/4377 [==============================] - 12s 3ms/step - loss: 1.5555 - val_loss: 2.0224\n",
      "Epoch 36/50\n",
      "4377/4377 [==============================] - 18s 4ms/step - loss: 1.5518 - val_loss: 1.8444\n",
      "Epoch 37/50\n",
      "4377/4377 [==============================] - 16s 4ms/step - loss: 1.5517 - val_loss: 2.0126\n",
      "Epoch 38/50\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5464 - val_loss: 1.9761\n",
      "Epoch 39/50\n",
      "4375/4377 [============================>.] - ETA: 0s - loss: 1.5435Restoring model weights from the end of the best epoch: 29.\n",
      "4377/4377 [==============================] - 13s 3ms/step - loss: 1.5438 - val_loss: 2.2338\n",
      "Epoch 39: early stopping\n",
      "Epoch 1/50\n",
      "7741/7741 [==============================] - 43s 5ms/step - loss: 130.9899 - val_loss: 225.2231\n",
      "Epoch 2/50\n",
      "7741/7741 [==============================] - 44s 6ms/step - loss: 119.1265 - val_loss: 247.5919\n",
      "Epoch 3/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 118.4187 - val_loss: 246.4199\n",
      "Epoch 4/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 117.8511 - val_loss: 196.9116\n",
      "Epoch 5/50\n",
      "7741/7741 [==============================] - 36s 5ms/step - loss: 117.5873 - val_loss: 168.8179\n",
      "Epoch 6/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 116.8182 - val_loss: 186.8341\n",
      "Epoch 7/50\n",
      "7741/7741 [==============================] - 39s 5ms/step - loss: 116.4835 - val_loss: 180.1366\n",
      "Epoch 8/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 116.9721 - val_loss: 237.0233\n",
      "Epoch 9/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 116.1937 - val_loss: 184.8546\n",
      "Epoch 10/50\n",
      "7741/7741 [==============================] - 34s 4ms/step - loss: 116.0509 - val_loss: 169.8820\n",
      "Epoch 11/50\n",
      "7741/7741 [==============================] - 38s 5ms/step - loss: 116.0947 - val_loss: 175.4064\n",
      "Epoch 12/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 115.4249 - val_loss: 177.0632\n",
      "Epoch 13/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 115.6348 - val_loss: 213.2104\n",
      "Epoch 14/50\n",
      "7741/7741 [==============================] - 37s 5ms/step - loss: 115.4744 - val_loss: 174.4273\n",
      "Epoch 15/50\n",
      "7737/7741 [============================>.] - ETA: 0s - loss: 115.7062Restoring model weights from the end of the best epoch: 5.\n",
      "7741/7741 [==============================] - 35s 5ms/step - loss: 115.7158 - val_loss: 190.5310\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_TSLA, X_test_TSLA = df_TSLA_train[features], df_TSLA_test[features]\n",
    "y_train_TSLA, y_test_TSLA = df_TSLA_train[target], df_TSLA_test[target]\n",
    "\n",
    "X_train_TSLA_scaled = scaler.fit_transform(X_train_TSLA)\n",
    "X_test_TSLA_scaled = scaler.transform(X_test_TSLA)\n",
    "\n",
    "input_shape = (len(features),)\n",
    "\n",
    "# Create sub-models for each moneyness category\n",
    "module_itm = create_module(input_shape, [128,128,128], 3, 'elu')\n",
    "module_atm = create_module(input_shape, [64, 128, 64], 3, 'relu')\n",
    "module_otm = create_module(input_shape, [128], 1, 'relu')\n",
    "\n",
    "# Compile each module\n",
    "module_itm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "module_atm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "module_otm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "\n",
    "# Train each module on its respective subset\n",
    "module_itm.fit(X_itm_TSLA_scaled, y_itm_TSLA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "module_atm.fit(X_atm_TSLA_scaled, y_atm_TSLA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "module_otm.fit(X_otm_TSLA_scaled, y_otm_TSLA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Define the combined model\n",
    "input_layer = Input(shape=input_shape)\n",
    "output_itm = module_itm(input_layer)\n",
    "output_atm = module_atm(input_layer)\n",
    "output_otm = module_otm(input_layer)\n",
    "\n",
    "combined_output = Concatenate()([output_itm, output_atm, output_otm])\n",
    "final_output = Dense(1, activation='linear')(combined_output)\n",
    "final_model_TSLA = Model(inputs=input_layer, outputs=final_output)\n",
    "\n",
    "# Compile the combined model\n",
    "final_model_TSLA.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0), loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# Fit the combined model to the full dataset (or a representative training set)\n",
    "history_final_TSLA = final_model_TSLA.fit(X_train_TSLA_scaled, y_train_TSLA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383bd569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting loss and validation loss\n",
    "train_loss_TSLA = history_final_TSLA.history['loss']\n",
    "val_loss_TSLA = history_final_TSLA.history['val_loss']\n",
    "\n",
    "epochs_range_TSLA = range(len(train_loss_TSLA))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs_range_TSLA, train_loss_TSLA, label='Training Loss for TSLA')\n",
    "plt.plot(epochs_range_TSLA, val_loss_TSLA, label='Validation Loss for TSLA')\n",
    "plt.title('Training and Validation Loss for TSLA')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf9e78",
   "metadata": {},
   "source": [
    "## RMSE for TSLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bc58a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151/2151 [==============================] - 6s 3ms/step\n",
      "RMSE for TSLA: 12.693567103111292\n"
     ]
    }
   ],
   "source": [
    "y_pred_TSLA = final_model_TSLA.predict(X_test_TSLA_scaled)\n",
    "test_rmse_TSLA = np.sqrt(mean_squared_error(y_test_TSLA, y_pred_TSLA))\n",
    "print('RMSE for TSLA:', test_rmse_TSLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c48be5",
   "metadata": {},
   "source": [
    "## Train Model for AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f850dacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1747/1747 [==============================] - 9s 4ms/step - loss: 99.7846 - val_loss: 43.7141\n",
      "Epoch 2/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 31.1150 - val_loss: 40.9638\n",
      "Epoch 3/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 29.8194 - val_loss: 41.6328\n",
      "Epoch 4/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 29.2456 - val_loss: 48.3078\n",
      "Epoch 5/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 28.9084 - val_loss: 43.4052\n",
      "Epoch 6/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 28.6012 - val_loss: 41.4234\n",
      "Epoch 7/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 28.3863 - val_loss: 37.9794\n",
      "Epoch 8/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 28.1959 - val_loss: 40.5272\n",
      "Epoch 9/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 27.9904 - val_loss: 38.3811\n",
      "Epoch 10/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 28.1029 - val_loss: 41.5615\n",
      "Epoch 11/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 27.5587 - val_loss: 37.6010\n",
      "Epoch 12/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 27.5455 - val_loss: 50.5077\n",
      "Epoch 13/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 27.7936 - val_loss: 42.7074\n",
      "Epoch 14/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 27.5449 - val_loss: 37.5807\n",
      "Epoch 15/50\n",
      "1747/1747 [==============================] - 6s 4ms/step - loss: 27.6459 - val_loss: 38.6339\n",
      "Epoch 16/50\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 27.7884 - val_loss: 44.2880\n",
      "Epoch 17/50\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 27.5192 - val_loss: 38.1924\n",
      "Epoch 18/50\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 27.6594 - val_loss: 39.4254\n",
      "Epoch 19/50\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 27.8321 - val_loss: 40.2054\n",
      "Epoch 20/50\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 27.4166 - val_loss: 41.3447\n",
      "Epoch 21/50\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 27.2126 - val_loss: 39.0282\n",
      "Epoch 22/50\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 27.3452 - val_loss: 38.1017\n",
      "Epoch 23/50\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 27.3314 - val_loss: 40.8456\n",
      "Epoch 24/50\n",
      "1739/1747 [============================>.] - ETA: 0s - loss: 27.0886Restoring model weights from the end of the best epoch: 14.\n",
      "1747/1747 [==============================] - 7s 4ms/step - loss: 27.0824 - val_loss: 38.4637\n",
      "Epoch 24: early stopping\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 3s 5ms/step - loss: 46.4862 - val_loss: 2.5378\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 1.7883 - val_loss: 2.2554\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 1.4659 - val_loss: 1.3263\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 1.2651 - val_loss: 1.0584\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 1.1319 - val_loss: 0.9298\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 1.0790 - val_loss: 0.9398\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 1.0215 - val_loss: 1.0417\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.9123 - val_loss: 0.9009\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.8831 - val_loss: 0.7691\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.8445 - val_loss: 0.7207\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.8229 - val_loss: 1.0482\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.7792 - val_loss: 0.7974\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.7735 - val_loss: 1.1627\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.7420 - val_loss: 0.6382\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.7597 - val_loss: 0.9307\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6922 - val_loss: 0.7291\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.7030 - val_loss: 0.6058\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6789 - val_loss: 0.5788\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6674 - val_loss: 1.0889\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6658 - val_loss: 0.7426\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6375 - val_loss: 0.7559\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6685 - val_loss: 0.7954\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6499 - val_loss: 0.5232\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6165 - val_loss: 0.5965\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6284 - val_loss: 0.4810\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6257 - val_loss: 0.6139\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5958 - val_loss: 0.4930\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5930 - val_loss: 0.4754\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6237 - val_loss: 0.4772\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5931 - val_loss: 0.4518\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6151 - val_loss: 0.5677\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5923 - val_loss: 0.4919\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5830 - val_loss: 1.0317\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5542 - val_loss: 0.4495\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5813 - val_loss: 0.4511\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5440 - val_loss: 0.9647\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6113 - val_loss: 0.7594\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5594 - val_loss: 0.4518\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5465 - val_loss: 0.4939\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5683 - val_loss: 0.6199\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5512 - val_loss: 0.6899\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5587 - val_loss: 0.7443\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5754 - val_loss: 0.4092\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5401 - val_loss: 0.7918\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5376 - val_loss: 1.0143\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5471 - val_loss: 0.6443\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5432 - val_loss: 0.6933\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5135 - val_loss: 0.6137\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5238 - val_loss: 0.5326\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.5163 - val_loss: 1.6525\n",
      "Epoch 1/50\n",
      "1858/1858 [==============================] - 7s 3ms/step - loss: 4.7701 - val_loss: 18.2445\n",
      "Epoch 2/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.7070 - val_loss: 18.0976\n",
      "Epoch 3/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.4786 - val_loss: 17.9284\n",
      "Epoch 4/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.3969 - val_loss: 18.0497\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.3474 - val_loss: 18.0211\n",
      "Epoch 6/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.3182 - val_loss: 17.9330\n",
      "Epoch 7/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.3019 - val_loss: 17.9097\n",
      "Epoch 8/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2843 - val_loss: 17.9890\n",
      "Epoch 9/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2769 - val_loss: 17.8782\n",
      "Epoch 10/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2649 - val_loss: 17.9019\n",
      "Epoch 11/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2570 - val_loss: 18.0903\n",
      "Epoch 12/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2478 - val_loss: 17.9446\n",
      "Epoch 13/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2417 - val_loss: 18.1064\n",
      "Epoch 14/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2388 - val_loss: 17.9103\n",
      "Epoch 15/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2340 - val_loss: 17.8615\n",
      "Epoch 16/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2291 - val_loss: 17.8755\n",
      "Epoch 17/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2259 - val_loss: 18.2556\n",
      "Epoch 18/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2223 - val_loss: 17.9725\n",
      "Epoch 19/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2183 - val_loss: 17.8620\n",
      "Epoch 20/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2162 - val_loss: 18.0734\n",
      "Epoch 21/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2153 - val_loss: 17.8991\n",
      "Epoch 22/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2113 - val_loss: 17.8656\n",
      "Epoch 23/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2091 - val_loss: 17.8759\n",
      "Epoch 24/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2102 - val_loss: 17.8104\n",
      "Epoch 25/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2055 - val_loss: 18.0079\n",
      "Epoch 26/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2027 - val_loss: 17.8070\n",
      "Epoch 27/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2043 - val_loss: 17.8118\n",
      "Epoch 28/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2009 - val_loss: 17.7819\n",
      "Epoch 29/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2037 - val_loss: 17.8742\n",
      "Epoch 30/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.2001 - val_loss: 17.7788\n",
      "Epoch 31/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1979 - val_loss: 17.8030\n",
      "Epoch 32/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1959 - val_loss: 17.8122\n",
      "Epoch 33/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1956 - val_loss: 17.9703\n",
      "Epoch 34/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1945 - val_loss: 17.7408\n",
      "Epoch 35/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1943 - val_loss: 18.1082\n",
      "Epoch 36/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1927 - val_loss: 18.0209\n",
      "Epoch 37/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1896 - val_loss: 18.0246\n",
      "Epoch 38/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1892 - val_loss: 17.7671\n",
      "Epoch 39/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1877 - val_loss: 17.9585\n",
      "Epoch 40/50\n",
      "1858/1858 [==============================] - 6s 3ms/step - loss: 0.1868 - val_loss: 17.8932\n",
      "Epoch 41/50\n",
      "1858/1858 [==============================] - 6s 3ms/step - loss: 0.1874 - val_loss: 17.9002\n",
      "Epoch 42/50\n",
      "1858/1858 [==============================] - 6s 3ms/step - loss: 0.1858 - val_loss: 18.0783\n",
      "Epoch 43/50\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1865 - val_loss: 17.7490\n",
      "Epoch 44/50\n",
      "1857/1858 [============================>.] - ETA: 0s - loss: 0.1848Restoring model weights from the end of the best epoch: 34.\n",
      "1858/1858 [==============================] - 5s 3ms/step - loss: 0.1848 - val_loss: 17.8277\n",
      "Epoch 44: early stopping\n",
      "Epoch 1/50\n",
      "3836/3836 [==============================] - 23s 5ms/step - loss: 49.2713 - val_loss: 26.1222\n",
      "Epoch 2/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 15.4317 - val_loss: 44.0729\n",
      "Epoch 3/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 15.1189 - val_loss: 26.4924\n",
      "Epoch 4/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 14.8795 - val_loss: 28.8557\n",
      "Epoch 5/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 14.5780 - val_loss: 29.2155\n",
      "Epoch 6/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 14.5421 - val_loss: 26.7672\n",
      "Epoch 7/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 14.4215 - val_loss: 25.0907\n",
      "Epoch 8/50\n",
      "3836/3836 [==============================] - 18s 5ms/step - loss: 14.2644 - val_loss: 25.1716\n",
      "Epoch 9/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 14.3652 - val_loss: 28.1477\n",
      "Epoch 10/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 14.1986 - val_loss: 30.6027\n",
      "Epoch 11/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 14.1242 - val_loss: 24.9577\n",
      "Epoch 12/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 14.0696 - val_loss: 34.9083\n",
      "Epoch 13/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 14.0390 - val_loss: 35.0493\n",
      "Epoch 14/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 13.9458 - val_loss: 26.6475\n",
      "Epoch 15/50\n",
      "3836/3836 [==============================] - 17s 5ms/step - loss: 13.9245 - val_loss: 25.1301\n",
      "Epoch 16/50\n",
      "3836/3836 [==============================] - 18s 5ms/step - loss: 14.0278 - val_loss: 25.2255\n",
      "Epoch 17/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 13.8505 - val_loss: 28.9845\n",
      "Epoch 18/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 13.8340 - val_loss: 30.0344\n",
      "Epoch 19/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 13.8308 - val_loss: 28.1286\n",
      "Epoch 20/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 13.8877 - val_loss: 30.1674\n",
      "Epoch 21/50\n",
      "3836/3836 [==============================] - 17s 5ms/step - loss: 13.7809 - val_loss: 24.8323\n",
      "Epoch 22/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 13.9049 - val_loss: 28.0699\n",
      "Epoch 23/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 13.7582 - val_loss: 25.8707\n",
      "Epoch 24/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 13.8805 - val_loss: 26.2562\n",
      "Epoch 25/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 13.7820 - val_loss: 26.5065\n",
      "Epoch 26/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 13.7930 - val_loss: 26.8955\n",
      "Epoch 27/50\n",
      "3836/3836 [==============================] - 19s 5ms/step - loss: 13.7505 - val_loss: 25.3408\n",
      "Epoch 28/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 13.6994 - val_loss: 29.5365\n",
      "Epoch 29/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 13.7156 - val_loss: 25.9350\n",
      "Epoch 30/50\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 13.5971 - val_loss: 33.4595\n",
      "Epoch 31/50\n",
      "3832/3836 [============================>.] - ETA: 0s - loss: 13.7063Restoring model weights from the end of the best epoch: 21.\n",
      "3836/3836 [==============================] - 17s 4ms/step - loss: 13.7029 - val_loss: 26.7785\n",
      "Epoch 31: early stopping\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_AAPL, X_test_AAPL = df_AAPL_train[features], df_AAPL_test[features]\n",
    "y_train_AAPL, y_test_AAPL = df_AAPL_train[target], df_AAPL_test[target]\n",
    "\n",
    "X_train_AAPL_scaled = scaler.fit_transform(X_train_AAPL)\n",
    "X_test_AAPL_scaled = scaler.transform(X_test_AAPL)\n",
    "\n",
    "input_shape = (len(features),)\n",
    "\n",
    "# Create sub-models for each moneyness category\n",
    "module_itm = create_module(input_shape, [128,128,128], 3, 'elu')\n",
    "module_atm = create_module(input_shape, [64, 128, 64], 3, 'relu')\n",
    "module_otm = create_module(input_shape, [128], 1, 'relu')\n",
    "\n",
    "# Compile each module\n",
    "module_itm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "module_atm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "module_otm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "\n",
    "# Train each module on its respective subset\n",
    "module_itm.fit(X_itm_AAPL_scaled, y_itm_AAPL, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "module_atm.fit(X_atm_AAPL_scaled, y_atm_AAPL, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "module_otm.fit(X_otm_AAPL_scaled, y_otm_AAPL, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Define the combined model\n",
    "input_layer = Input(shape=input_shape)\n",
    "output_itm = module_itm(input_layer)\n",
    "output_atm = module_atm(input_layer)\n",
    "output_otm = module_otm(input_layer)\n",
    "\n",
    "combined_output = Concatenate()([output_itm, output_atm, output_otm])\n",
    "final_output = Dense(1, activation='linear')(combined_output)\n",
    "final_model_AAPL = Model(inputs=input_layer, outputs=final_output)\n",
    "\n",
    "# Compile the combined model\n",
    "final_model_AAPL.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0), loss='mean_squared_error')\n",
    "\n",
    "# Fit the combined model to the full dataset (or a representative training set)\n",
    "history_final_AAPL = final_model_AAPL.fit(X_train_AAPL_scaled, y_train_AAPL, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ffec629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting loss and validation loss\n",
    "train_loss_AAPL = history_final_AAPL.history['loss']\n",
    "val_loss_AAPL = history_final_AAPL.history['val_loss']\n",
    "\n",
    "epochs_range_AAPL = range(len(train_loss_AAPL))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs_range_AAPL, train_loss_AAPL, label='Training Loss for AAPL')\n",
    "plt.plot(epochs_range_AAPL, val_loss_AAPL, label='Validation Loss for AAPL')\n",
    "plt.title('Training and Validation Loss for AAPL')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565d555",
   "metadata": {},
   "source": [
    "## RMSE for AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4604b987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 3s 3ms/step\n",
      "RMSE for AAPL: 3.541125359395983\n"
     ]
    }
   ],
   "source": [
    "y_pred_AAPL = final_model_AAPL.predict(X_test_AAPL_scaled)\n",
    "test_rmse_AAPL = np.sqrt(mean_squared_error(y_test_AAPL, y_pred_AAPL))\n",
    "print('RMSE for AAPL:', test_rmse_AAPL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cdd1bf",
   "metadata": {},
   "source": [
    "## Train Model for NVDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "381f2d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3346/3346 [==============================] - 14s 4ms/step - loss: 1227.4943 - val_loss: 1504.5750\n",
      "Epoch 2/50\n",
      "3346/3346 [==============================] - 12s 4ms/step - loss: 896.1353 - val_loss: 1601.0978\n",
      "Epoch 3/50\n",
      "3346/3346 [==============================] - 12s 3ms/step - loss: 876.0663 - val_loss: 1508.8811\n",
      "Epoch 4/50\n",
      "3346/3346 [==============================] - 12s 3ms/step - loss: 864.4077 - val_loss: 1821.3181\n",
      "Epoch 5/50\n",
      "3346/3346 [==============================] - 13s 4ms/step - loss: 852.8129 - val_loss: 1641.4692\n",
      "Epoch 6/50\n",
      "3346/3346 [==============================] - 13s 4ms/step - loss: 847.3801 - val_loss: 1350.4865\n",
      "Epoch 7/50\n",
      "3346/3346 [==============================] - 12s 4ms/step - loss: 843.9732 - val_loss: 1388.7991\n",
      "Epoch 8/50\n",
      "3346/3346 [==============================] - 12s 4ms/step - loss: 836.4954 - val_loss: 1606.1942\n",
      "Epoch 9/50\n",
      "3346/3346 [==============================] - 13s 4ms/step - loss: 834.1115 - val_loss: 1552.4498\n",
      "Epoch 10/50\n",
      "3346/3346 [==============================] - 13s 4ms/step - loss: 834.1617 - val_loss: 1584.0870\n",
      "Epoch 11/50\n",
      "3346/3346 [==============================] - 13s 4ms/step - loss: 833.7932 - val_loss: 1416.5350\n",
      "Epoch 12/50\n",
      "3346/3346 [==============================] - 13s 4ms/step - loss: 837.8118 - val_loss: 1404.1824\n",
      "Epoch 13/50\n",
      "3346/3346 [==============================] - 13s 4ms/step - loss: 833.7640 - val_loss: 1620.4064\n",
      "Epoch 14/50\n",
      "3346/3346 [==============================] - 12s 4ms/step - loss: 831.8738 - val_loss: 1810.4868\n",
      "Epoch 15/50\n",
      "3346/3346 [==============================] - 12s 4ms/step - loss: 830.6815 - val_loss: 1551.7192\n",
      "Epoch 16/50\n",
      "3346/3346 [==============================] - 12s 3ms/step - loss: 824.7078 - val_loss: 1321.4202\n",
      "Epoch 17/50\n",
      "3346/3346 [==============================] - 12s 4ms/step - loss: 821.3063 - val_loss: 1358.3696\n",
      "Epoch 18/50\n",
      "3346/3346 [==============================] - 12s 3ms/step - loss: 816.1240 - val_loss: 1481.3848\n",
      "Epoch 19/50\n",
      "3346/3346 [==============================] - 12s 4ms/step - loss: 818.5232 - val_loss: 1383.7590\n",
      "Epoch 20/50\n",
      "3346/3346 [==============================] - 12s 4ms/step - loss: 822.1353 - val_loss: 1353.1616\n",
      "Epoch 21/50\n",
      "3346/3346 [==============================] - 12s 3ms/step - loss: 827.5580 - val_loss: 1460.0160\n",
      "Epoch 22/50\n",
      "3346/3346 [==============================] - 12s 4ms/step - loss: 831.0562 - val_loss: 1323.5715\n",
      "Epoch 23/50\n",
      "3346/3346 [==============================] - 12s 3ms/step - loss: 828.1884 - val_loss: 1322.4508\n",
      "Epoch 24/50\n",
      "3346/3346 [==============================] - 13s 4ms/step - loss: 826.1506 - val_loss: 1392.2754\n",
      "Epoch 25/50\n",
      "3346/3346 [==============================] - 13s 4ms/step - loss: 824.5984 - val_loss: 1389.5439\n",
      "Epoch 26/50\n",
      "3334/3346 [============================>.] - ETA: 0s - loss: 822.6556Restoring model weights from the end of the best epoch: 16.\n",
      "3346/3346 [==============================] - 14s 4ms/step - loss: 823.3295 - val_loss: 1331.6600\n",
      "Epoch 26: early stopping\n",
      "Epoch 1/50\n",
      "348/348 [==============================] - 4s 5ms/step - loss: 461.8656 - val_loss: 54.3953\n",
      "Epoch 2/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 12.3990 - val_loss: 28.2955\n",
      "Epoch 3/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 10.8979 - val_loss: 28.2313\n",
      "Epoch 4/50\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 10.4516 - val_loss: 28.9518\n",
      "Epoch 5/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 10.2050 - val_loss: 28.8464\n",
      "Epoch 6/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 10.7800 - val_loss: 28.8490\n",
      "Epoch 7/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 10.0817 - val_loss: 30.6874\n",
      "Epoch 8/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.7616 - val_loss: 30.1931\n",
      "Epoch 9/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.8181 - val_loss: 30.1605\n",
      "Epoch 10/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.8101 - val_loss: 27.7164\n",
      "Epoch 11/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.3944 - val_loss: 34.5356\n",
      "Epoch 12/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.5258 - val_loss: 30.3522\n",
      "Epoch 13/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.6780 - val_loss: 38.9850\n",
      "Epoch 14/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.1751 - val_loss: 30.6765\n",
      "Epoch 15/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.6453 - val_loss: 33.1385\n",
      "Epoch 16/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.4586 - val_loss: 29.0611\n",
      "Epoch 17/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.1113 - val_loss: 31.7983\n",
      "Epoch 18/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 9.2813 - val_loss: 30.7247\n",
      "Epoch 19/50\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 8.9448 - val_loss: 31.7206\n",
      "Epoch 20/50\n",
      "344/348 [============================>.] - ETA: 0s - loss: 9.0015Restoring model weights from the end of the best epoch: 10.\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 8.9843 - val_loss: 35.9593\n",
      "Epoch 20: early stopping\n",
      "Epoch 1/50\n",
      "3207/3207 [==============================] - 11s 3ms/step - loss: 91.4746 - val_loss: 28.7413\n",
      "Epoch 2/50\n",
      "3207/3207 [==============================] - 10s 3ms/step - loss: 19.7127 - val_loss: 28.6892\n",
      "Epoch 3/50\n",
      "3207/3207 [==============================] - 10s 3ms/step - loss: 18.7515 - val_loss: 29.6730\n",
      "Epoch 4/50\n",
      "3207/3207 [==============================] - 10s 3ms/step - loss: 18.1196 - val_loss: 27.0810\n",
      "Epoch 5/50\n",
      "3207/3207 [==============================] - 10s 3ms/step - loss: 17.6108 - val_loss: 26.2358\n",
      "Epoch 6/50\n",
      "3207/3207 [==============================] - 10s 3ms/step - loss: 17.2588 - val_loss: 26.6586\n",
      "Epoch 7/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 16.9568 - val_loss: 26.9539\n",
      "Epoch 8/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 16.7072 - val_loss: 26.6012\n",
      "Epoch 9/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 16.5351 - val_loss: 26.5916\n",
      "Epoch 10/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 16.3888 - val_loss: 25.1610\n",
      "Epoch 11/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 16.3193 - val_loss: 26.8045\n",
      "Epoch 12/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 16.1420 - val_loss: 25.3625\n",
      "Epoch 13/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 16.0740 - val_loss: 31.1209\n",
      "Epoch 14/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 15.9828 - val_loss: 25.6835\n",
      "Epoch 15/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 15.9475 - val_loss: 27.6293\n",
      "Epoch 16/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 15.8514 - val_loss: 27.0780\n",
      "Epoch 17/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 15.7915 - val_loss: 27.8946\n",
      "Epoch 18/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 15.7408 - val_loss: 30.4061\n",
      "Epoch 19/50\n",
      "3207/3207 [==============================] - 9s 3ms/step - loss: 15.7409 - val_loss: 27.9970\n",
      "Epoch 20/50\n",
      "3197/3207 [============================>.] - ETA: 0s - loss: 15.6927Restoring model weights from the end of the best epoch: 10.\n",
      "3207/3207 [==============================] - 10s 3ms/step - loss: 15.6793 - val_loss: 29.2558\n",
      "Epoch 20: early stopping\n",
      "Epoch 1/50\n",
      "6900/6900 [==============================] - 42s 5ms/step - loss: 514.1074 - val_loss: 740.3640\n",
      "Epoch 2/50\n",
      "6900/6900 [==============================] - 36s 5ms/step - loss: 440.3551 - val_loss: 825.3958\n",
      "Epoch 3/50\n",
      "6900/6900 [==============================] - 36s 5ms/step - loss: 434.6026 - val_loss: 859.2378\n",
      "Epoch 4/50\n",
      "6900/6900 [==============================] - 31s 4ms/step - loss: 430.3043 - val_loss: 761.0246\n",
      "Epoch 5/50\n",
      "6900/6900 [==============================] - 31s 4ms/step - loss: 429.8529 - val_loss: 688.2346\n",
      "Epoch 6/50\n",
      "6900/6900 [==============================] - 31s 4ms/step - loss: 430.1710 - val_loss: 719.0196\n",
      "Epoch 7/50\n",
      "6900/6900 [==============================] - 32s 5ms/step - loss: 431.2238 - val_loss: 609.2600\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6900/6900 [==============================] - 36s 5ms/step - loss: 432.5413 - val_loss: 703.3654\n",
      "Epoch 9/50\n",
      "6900/6900 [==============================] - 36s 5ms/step - loss: 433.4214 - val_loss: 700.1241\n",
      "Epoch 10/50\n",
      "6900/6900 [==============================] - 36s 5ms/step - loss: 432.0304 - val_loss: 889.1140\n",
      "Epoch 11/50\n",
      "6900/6900 [==============================] - 32s 5ms/step - loss: 434.1501 - val_loss: 631.0456\n",
      "Epoch 12/50\n",
      "6900/6900 [==============================] - 31s 4ms/step - loss: 432.6372 - val_loss: 680.3149\n",
      "Epoch 13/50\n",
      "6900/6900 [==============================] - 31s 5ms/step - loss: 432.8771 - val_loss: 670.2618\n",
      "Epoch 14/50\n",
      "6900/6900 [==============================] - 31s 4ms/step - loss: 432.0909 - val_loss: 676.5604\n",
      "Epoch 15/50\n",
      "6900/6900 [==============================] - 37s 5ms/step - loss: 433.7485 - val_loss: 700.3364\n",
      "Epoch 16/50\n",
      "6900/6900 [==============================] - 36s 5ms/step - loss: 431.9131 - val_loss: 1004.7169\n",
      "Epoch 17/50\n",
      "6891/6900 [============================>.] - ETA: 0s - loss: 432.3094Restoring model weights from the end of the best epoch: 7.\n",
      "6900/6900 [==============================] - 36s 5ms/step - loss: 432.2123 - val_loss: 712.2421\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_NVDA, X_test_NVDA = df_NVDA_train[features], df_NVDA_test[features]\n",
    "y_train_NVDA, y_test_NVDA = df_NVDA_train[target], df_NVDA_test[target]\n",
    "\n",
    "X_train_NVDA_scaled = scaler.fit_transform(X_train_NVDA)\n",
    "X_test_NVDA_scaled = scaler.transform(X_test_NVDA)\n",
    "\n",
    "input_shape = (len(features),)\n",
    "\n",
    "# Create sub-models for each moneyness category\n",
    "module_itm = create_module(input_shape, [128,128,128], 3, 'elu')\n",
    "module_atm = create_module(input_shape, [64, 128, 64], 3, 'relu')\n",
    "module_otm = create_module(input_shape, [128], 1, 'relu')\n",
    "\n",
    "# Compile each module\n",
    "module_itm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "module_atm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "module_otm.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "\n",
    "# Train each module on its respective subset\n",
    "module_itm.fit(X_itm_NVDA_scaled, y_itm_NVDA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "module_atm.fit(X_atm_NVDA_scaled, y_atm_NVDA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "module_otm.fit(X_otm_NVDA_scaled, y_otm_NVDA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Define the combined model\n",
    "input_layer = Input(shape=input_shape)\n",
    "output_itm = module_itm(input_layer)\n",
    "output_atm = module_atm(input_layer)\n",
    "output_otm = module_otm(input_layer)\n",
    "\n",
    "combined_output = Concatenate()([output_itm, output_atm, output_otm])\n",
    "final_output = Dense(1, activation='linear')(combined_output)\n",
    "final_model_NVDA = Model(inputs=input_layer, outputs=final_output)\n",
    "\n",
    "# Compile the combined model\n",
    "final_model_NVDA.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0), loss='mean_squared_error')\n",
    "\n",
    "# Fit the combined model to the full dataset (or a representative training set)\n",
    "history_final_NVDA = final_model_NVDA.fit(X_train_NVDA_scaled, y_train_NVDA, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fa13c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting loss and validation loss\n",
    "train_loss_NVDA = history_final_NVDA.history['loss']\n",
    "val_loss_NVDA = history_final_NVDA.history['val_loss']\n",
    "\n",
    "epochs_range_NVDA = range(len(train_loss_NVDA))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs_range_NVDA, train_loss_NVDA, label='Training Loss for NVDA')\n",
    "plt.plot(epochs_range_NVDA, val_loss_NVDA, label='Validation Loss for NVDA')\n",
    "plt.title('Training and Validation Loss for NVDA')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1bd8e",
   "metadata": {},
   "source": [
    "## RMSE for NVDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a018238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1917/1917 [==============================] - 6s 3ms/step\n",
      "RMSE for NVDA: 24.175006041795665\n"
     ]
    }
   ],
   "source": [
    "y_pred_NVDA = final_model_NVDA.predict(X_test_NVDA_scaled)\n",
    "test_rmse_NVDA = np.sqrt(mean_squared_error(y_test_NVDA, y_pred_NVDA))\n",
    "print('RMSE for NVDA:', test_rmse_NVDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852bedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
